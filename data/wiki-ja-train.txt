自然言語処理（しぜんげんごしょり、英語：　ｎａｔｕｒａｌ　ｌａｎｇｕａｇｅ　ｐｒｏｃｅｓｓｉｎｇ、略称：ＮＬＰ）は、人間が日常的に使っている自然言語をコンピュータに処理させる一連の技術であり、人工知能と言語学の一分野である。
「計算言語学」（ｃｏｍｐｕｔａｔｉｏｎａｌ　ｌｉｎｇｕｉｓｔｉｃｓ）も同じ意味であるが、前者は工学的な視点からの言語処理をさすのに対して、後者は言語学的視点を重視する手法をさす事が多い。
データベース内の情報を自然言語に変換したり、自然言語の文章をより形式的な（コンピュータが理解しやすい）表現に変換するといった処理が含まれる。
自然言語の理解をコンピュータにさせることは、自然言語理解とされている。
自然言語理解と、自然言語処理の差は、意味を扱うか、扱わないかという説もあったが、最近は数理的な言語解析手法（統計や確率など）が広められた為、パーサ（統語解析器）などが一段と精度や速度が上がり、その意味合いは違ってきている。
もともと自然言語の意味論的側面を全く無視して達成できることは非常に限られている。
このため、自然言語処理には形態素解析と構文解析、文脈解析、意味解析などをＳｙｎｔａｘなど表層的な観点から解析をする学問であるが、自然言語理解は、意味をどのように理解するかという個々人の理解と推論部分が主な研究の課題になってきており、両者の境界は意思や意図が含まれるかどうかになってきている。
目次
１　基礎技術
２　処理内容とその限界
３　具体的な課題
４　統計的自然言語処理
５　自然言語処理の主な応用
６　脚注
７　関連項目
８　外部リンク
基礎技術
自然言語処理の基礎技術にはさまざまなものがある。
自然言語処理はその性格上、扱う言語によって大きく処理の異なる部分がある。
現在のところ、日本語を処理する基礎技術としては以下のものが主に研究されている。
形態素解析
構文解析
語義の曖昧性解消
照応解析
処理内容とその限界
理論上、自然言語処理はマンマシンインタフェースの手法として非常に魅力的である。
ＳＨＲＤＬＵなどの初期のシステムは世界を限定することで非常にうまくいったため、自然言語処理は簡単だという行き過ぎた楽観主義に陥ったが、より現実的な世界では曖昧さや複雑さが増大し、楽観的な見方はなくなっていった。
自然言語理解は、ＡＩ完全問題と言われることがある。
なぜなら、自然言語理解には世界全体についての知識とそれを操作する能力が必要と思われるためである。
「理解;　ｕｎｄｅｒｓｔａｎｄｉｎｇ」の定義は、自然言語処理の大きな課題のひとつでもある。
具体的な課題
自然言語処理（理解）における課題をいくつかの例を用いて示す。
次の２つの文、
Ｗｅ　ｇａｖｅ　ｔｈｅ　ｍｏｎｋｅｙｓ　ｔｈｅ　ｂａｎａｎａｓ　ｂｅｃａｕｓｅ　ｔｈｅｙ　ｗｅｒｅ　ｈｕｎｇｒｙ．（猿が腹を空かせていたので、バナナを与えた。
）
Ｗｅ　ｇａｖｅ　ｔｈｅ　ｍｏｎｋｅｙｓ　ｔｈｅ　ｂａｎａｎａｓ　ｂｅｃａｕｓｅ　ｔｈｅｙ　ｗｅｒｅ　ｏｖｅｒーｒｉｐｅ．（バナナは熟れ過ぎていたので、猿に与えた。
）
は表面的な文法構造は同じである。
しかし、ｔｈｅｙ　が指すものは異なっていて、前者では猿、後者ではバナナとなっている。
この例文の場合、ｔｈｅｙの指す内容は英語の文型の性質によって決定することができる。
すなわち、「ｔｈｅｙ（主語）=　ｈｕｎｇｒｙ（補語）」の関係が成り立ち、補語には主語の性質を示すものがくるので、ｈｕｎｇｒｙなのはｔｈｅ　ｍｏｎｋｅｙｓ、したがって、「ｔｈｅｙ　=　ｔｈｅ　ｍｏｎｋｅｙｓ」と決まる。
後者も同様に、ｏｖｅｒーｒｉｐｅというのはｔｈｅ　ｂａｎａｎａｓの性質だから、「ｔｈｅｙ　=　ｔｈｅ　ｂａｎａｎａｓ」となる。
つまり、これらの文章を区別し正しく理解するためには、猿の性質（猿は動物で空腹になる）とバナナの性質（バナナは果物で成熟する）を知っていなければならない。
単語の文字列を解釈する方法は様々である。
例えば、
Ｔｉｍｅ　ｆｌｉｅｓ　ｌｉｋｅ　ａｎ　ａｒｒｏｗ．（光陰矢の如し）
という文字列は以下のように様々に解釈できる。
典型的には、比喩として、「時間が矢のように素早く過ぎる」と解釈する。
「空を飛ぶ昆虫の速度を矢の速度を測るように測定せよ」つまり　（Ｙｏｕ　ｓｈｏｕｌｄ）　ｔｉｍｅ　ｆｌｉｅｓ　ａｓ　ｙｏｕ　ｗｏｕｌｄ　（ｔｉｍｅ）　ａｎ　ａｒｒｏｗ．　と解釈する。
「矢が空を飛ぶ昆虫の速度を測るように、あなたが空を飛ぶ昆虫の速度を測定せよ」つまり　Ｔｉｍｅ　ｆｌｉｅｓ　ｉｎ　ｔｈｅ　ｓａｍｅ　ｗａｙ　ｔｈａｔ　ａｎ　ａｒｒｏｗ　ｗｏｕｌｄ　（ｔｉｍｅ　ｔｈｅｍ）．　と解釈する。
「矢のように空を飛ぶ昆虫の速度を測定せよ」つまり　Ｔｉｍｅ　ｔｈｏｓｅ　ｆｌｉｅｓ　ｔｈａｔ　ａｒｅ　ｌｉｋｅ　ａｒｒｏｗｓ　と解釈する。
「”ｔｉｍｅーｆｌｉｅｓ”（時バエ）という種類の昆虫は１つの矢を好む」この解釈には集合的な解釈と個別的解釈がありうる。
「ＴＩＭＥという雑誌は、投げると直線的な軌跡を描く」
英語では特に語形変化による語彙の区別をする機能が弱いため、このような問題が大きくなる。
また、英語も含めて、形容詞と名詞の修飾関係の曖昧さもある。
例えば、”ｐｒｅｔｔｙ　ｌｉｔｔｌｅ　ｇｉｒｌｓ'　ｓｃｈｏｏｌ”（かわいい小さな少女の学校）という文字列があるとする。
その学校は小さいだろうか？
少女たちが小さいのだろうか？
少女たちがかわいいのだろうか？
学校がかわいいのだろうか？
他にも次のような課題がある。
形態素解析
中国語、日本語、タイ語といった言語は単語のわかち書きをしない。
そのため、単語の区切りを特定するのにテキストの解析が必要となり、それは非常に複雑な作業となる。
音声における形態素解析
音声言語において、文字を表す音は前後の音と混じっているのが普通である。
従って音声から文字を切り出すのは、非常に難しい作業となる。
さらに、音声言語では単語と単語の区切りも（音としてのみ見れば）定かではなく、文脈や文法や意味といった情報を考慮しないと単語を切り出せない。
語義の曖昧性
多くの単語は複数の意味を持つ。
従って、特定の文脈においてもっともふさわしい意味を選択する必要がある。
構文の曖昧性
自然言語の文法は曖昧である。
１つの文に対応する複数の構文木が存在することも多い。
もっとも適切な解釈（構文木）を選択するには、意味的情報や文脈情報を必要とする。
不完全な入力や間違った入力
主語の省略や代名詞の対応などの問題（照応解析）。
音声におけるアクセントのばらつき。
文法上の誤りのある文の解析。
光学文字認識における誤りの認識など。
言語行為
文章は文字通りに解釈できない場合がある。
例えば　”Ｃａｎ　ｙｏｕ　ｐａｓｓ　ｔｈｅ　ｓａｌｔ？”（塩をとってもらえますか？）という問いに対する答えは、塩を相手に渡すことである。
これに　”Ｙｅｓ”　とだけ答えて何もしないのはよい答えとは言えないが、”Ｎｏ”　はむしろありうる答えで、”Ｉ'ｍ　ａｆｒａｉｄ　ｔｈａｔ　Ｉ　ｃａｎ'ｔ　ｓｅｅ　ｉｔ”　はさらによい（塩がどこにあるかわからないとき）。
統計的自然言語処理
統計的自然言語処理は、確率論的あるいは統計学的手法を使って、上述の困難さに何らかの解決策を与えようとするものである。
長い文になればなるほど、従来型の自然言語処理では解釈の可能性の組合せが指数関数的に増大していき、処理が困難となる。
そのような場合に統計的自然言語処理が効果を発揮する。
コーパス言語学やマルコフ連鎖といった手法が使われる。
統計的自然言語処理の起源は、人工知能の中でもデータからの学習を研究する分野である機械学習やデータマイニングといった分野である。
自然言語処理の主な応用
自然言語処理の応用技術として、以下のような技術が研究・実用化されている。
また、言語学への応用も考えられている。
自動要約生成
情報抽出
情報検索、検索エンジン、概念検索
機械翻訳、翻訳ソフト
固有表現抽出
自然言語生成
光学文字認識
質問応答システム
音声認識
音声合成
校正、スペルチェッカ
かな漢字変換
自動要約生成（じどうようやくせいせい）とは、ひとつもしくは複数の文章の趣旨を要約して表示する方法である。
重要語や接続詞などを手がかりとしながら要約文を作成する。
重要な段落を抜き出す方法から、文の要点を抜き出す方法まで及ぶ。
身近なものとしてはＭｉｃｒｏｓｏｆｔ　Ｗｏｒｄの要約にマーカをつけるものがある。
しかし精度は３０％ぐらいだという。
アルゴリズム
自動要約処理のアルゴリズムは、昔から研究されており、多くのものが、文の重要度というものを計算して、その重要度が高い文を選んで、要約を行うというアルゴリズムが基本である。
文の重要度を計算する方法として、考えられているのは、文の中の単語が重要かどうかを判断する方法、文が文章中のどの位置にあるかを判断する方法などがある。
　今のところ、文章中の文の位置から、重要かどうかを考えることがもっとも有効と考えられている。
情報抽出は、情報ルーティングの分野のひとつである。
特定の文章やサイトから必要な情報をフィルタリングなどを通して取得する方法である。
ただ機械的に抜き出すこともあるが、自然言語処理を用いることもある。
情報抽出を行うことは困難な問題であるため、現在は非常に狭い分野でだけ適用できる方法が主流である。
情報検索（じょうほうけんさく）とは、コンピュータを用いて大量のデータ群から目的に合致したものを取り出すこと。
検索の対象となるデータには文書や画像、音声、映像、その他さまざまなメディアやその組み合わせとして記録されたデータなどが含まれる。
インターネットの発達により検索はインターネットを介して行われることも多いが、ここでは情報を検索するためのコンピュータ側における仕組みを記述している。
情報検索に対するコンピュータ側における技術は情報を人間が直接管理するのに比べ、データの量的な制約やデータの取り扱いの一貫性を保つ困難さという制約を受けることなく、高速で安定なシステムにより利用者に適切なデータを提供する機能と位置付けることができる。
目次
１　情報検索と情報検索システムの全体像
１．１　歴史と現在の課題
１．２　情報検索システムの構成要素
１．３　情報検索システム構築の手続き
１．３．１　検索対象データ収集
１．３．２　検索対象のデータからのメタデータ作成
１．３．３　検索アルゴリズムの設計
１．３．４　検索性能の評価
２　情報検索技術の分類
２．１　検索対象データの抽象度
２．２　検索入力の種類
３　検索アルゴリズム
４　関連項目
５　参考文献
６　脚注
７　外部リンク
７．１　オープンソースの情報検索システムソフトウェア
７．２　主な学術団体
７．３　その他
情報検索と情報検索システムの全体像
情報検索が基盤としている技術は多数の分野にのぼる。
情報検索はデータの管理および入出力のためのデータベース、文書データ処理のための自然言語処理や計算言語学、画像や音声を扱うための信号処理や認知心理学を背景とするパターン認識技術、メタデータに関する考察の基盤となった図書館情報学、検索アルゴリズム設計や情報検索システムの評価尺度考案のヒントとして寄与した諸数学理論などのさまざまな要素技術の組み合わせによって成り立っている。
情報検索システムは情報検索を実現するためのソフトウェアやハードウェアによって構成されるシステムである。
ここでは主にソフトウェアに関して、現在よく用いられているシステムの構成について述べる。
歴史と現在の課題
情報検索システムは１９７０年代に、大規模に蓄積される学術文献や論文等の管理をコンピュータ上で行うために、規模の大きい図書館でデータの管理と検索が行われるようになったのが起源である。
図書館における蔵書検索や電子ジャーナル、統計資料のデータベースなどへの応用は現在でも盛んに用いられているほか、１９９０年代から広まったＧｏｏｇｌｅやｇｏｏのようなＷｏｒｌｄ　Ｗｉｄｅ　Ｗｅｂ上のデータを対象にした検索エンジンが現在では情報検索のシステムとして特に身近な存在となっている。
２０００年代以降の情報検索の課題は、例として以下のようにまとめることができる。
いわゆるＤｅｅｐ　Ｗｅｂ（ショッピングサイトなどに代表される、バックエンドの大規模なデータベースが動的なコンテンツを生成するウェブサイト）を対象にした検索
より直感的なユーザインタフェース
より人間に近い高度な判断尺度を持ったマルチメディア情報検索
さまざまなメディアを統合的かつ横断的に扱うクロスメディア情報検索
格納されるデータや検索入力が言語に依存しないマルチリンガル（クロスリンガル）検索環境
Ｐ２Ｐネットワーク等の大規模分散データを対象にした情報検索
情報検索システムの構成要素
情報検索システムの全体像
情報検索システムは主に以下に挙げる要素によって構成されている。
データベース
検索対象のデータ
メタデータ（索引語）
ユーザインタフェース
検索アルゴリズム
データベースは検索対象のデータを蓄積し、管理している。
検索対象のデータからはメタデータが作成され、メタデータもデータベースに格納される。
検索の利用者は検索語（検索文）をユーザインタフェースを通して検索を発行し、検索アルゴリズムが適切なデータをデータベースに格納されているメタデータから選択し、選択されたメタデータに対応する検索対象のデータをユーザインタフェースを通して利用者に返答する。
例えばウェブサイトの情報検索では、検索対象のデータが個々のウェブサイトの内容、メタデータがウェブサイトの内容の要約やキーワード・紹介文、ユーザーインターフェースと検索アルゴリズムが検索エンジンにあたる。
検索エンジンは検索キーワードに一致するメタデータをデータベースから選択し、選択されたメタデータに対応する検索対象のデータを検索結果に表示する。
情報検索システム構築の手続き
情報検索システムの構築は以下のフェーズを経て行われる。
順序は必ずしも一定ではなく、構築するシステムの内容や外的環境によって異なる。
検索対象データ収集
検索の対象とするデータの収集方針を決定する。
Ｗｏｒｌｄ　Ｗｉｄｅ　Ｗｅｂ上のハイパーテキストを収集して対象とする場合にはクローラ（ロボット、スパイダー）を用いて自動的な収集を行うのが一般的であるが、天文学的数量の膨大なデータが存在し、かつ急激に変化するＷｏｒｌｄ　Ｗｉｄｅ　Ｗｅｂのデータを全て網羅して収集することは事実上不可能である。
そのため、いかにして網羅的に多くの対象のデータを収集するかが重要な課題となっており、Ｗｏｒｌｄ　Ｗｉｄｅ　Ｗｅｂ検索エンジンのサービスでは何ページのデータか検索が可能であるかが性能の指標の一つとなっている。
検索対象のデータからのメタデータ作成
検索対象のデータからのメタデータを作成する。
メタデータの形式および作成方法は検索アルゴリズムやデータ収集の方針と密接に関連する。
たとえばデータ収集が継続的かつ大規模に行われるような場合、人手を使ってメタデータを作成することはコストの大幅な増大を意味することになる。
検索アルゴリズムの設計
作成されたメタデータを用いてどのような計算を用いてデータを出力するか決定する。
検索アルゴリズムの詳細についてはメタデータ生成法と情報検索アルゴリズムを参照。
検索性能の評価
再現率と適合率
情報検索システムの検索性能の評価を行う。
情報検索システムの検索性能は主に正確性と網羅性の質的な観点から適合率（ｐｒｅｃｉｓｉｏｎ;精度ともいう）と再現率（ｒｅｃａｌｌ）を、処理性能の量的な観点からスループットを測定することにより判定するのが一般的である。
適合率は検索結果として得られた集合中にどれだけ検索に適合した文書を含んでいるかという正確性の指標であり、再現率は検索対象としている文書の中で検索結果として適合している文書（正解文書）のうちでどれだけの文書を検索できているかという網羅性の指標である。
適合率は、
ｐｒｅｃｉｓｉｏｎ　=　\ｆｒａｃ｛Ｒ｝｛Ｎ｝
（Ｒ：検索された適合文書の数、Ｎ：検索結果の文書の数）　によって、再現率は、
ｒｅｃａｌｌ　=　\ｆｒａｃ｛Ｒ｝｛Ｃ｝
（Ｒ：検索された適合文書の数、Ｃ：全対象文書中の正解文書の数）　によって求められる。
適合率をあげれば再現率が下がり、再現率を上げれば適合率が下がる傾向にあるため、Ｆ値（Ｆーｍｅａｓｕｒｅ）という尺度もよく用いられる。
Ｆ値は適合率と再現率の調和平均であり、
\ｂｅｇｉｎ｛ａｌｉｇｎ｝　Ｆ｛\ｔｅｘｔｉｔ｛ー｝｝ｍｅａｓｕｒｅ　＆　=　\ｆｒａｃ｛２　\ｃｄｏｔ　ｐｒｅｃｉｓｉｏｎ　\ｃｄｏｔ　ｒｅｃａｌｌ｝｛ｐｒｅｃｉｓｉｏｎ　＋　ｒｅｃａｌｌ｝　\\　＆　=　\ｆｒａｃ｛Ｒ｝｛\ｆｒａｃ｛１｝｛２｝　（Ｎ　＋　Ｃ）｝　\\　\ｅｎｄ｛ａｌｉｇｎ｝
によって求められ、ＲをＮとＣの相加平均で割ったものに相当する。
Ｆ値が高ければ、性能が良いことを意味する。
情報検索技術の分類
情報検索の技術は以下のような観点で分類できる。
検索対象データの抽象度
直接検索
メタデータを介さずデータそのものを直接計算アルゴリズム上で処理する検索方法。
例としてハミングによる検索の入力を行い類似する音程の音楽を検索するもの等。
実用上は、前処理としての索引の生成を事前におこなう方式も多いが、このような場合もデータに含まれる表現をそのまま用いて検索を行うため検索モデルとしては直接検索に分類される。
全文検索
直接検索の一種であり、文書データの全文から自動処理の走査によりメタデータを作成して保管し、検索の入力に合致するデータを検索結果とする検索方法。
「全文検索システムＮａｍａｚｕ」等が用いられている。
間接検索
データベースに蓄積されたデータからメタデータを生成して保管し、検索の入力が行われた際に内部表現に変換された検索の入力と保管されたメタデータを比較することにより検索結果を生成する検索方法。
検索入力の種類
単語（キーワード）
単語（キーワード）を指定することによって検索を行う。
もっとも単純な形式と言える。
検索言語
システム特有の検索言語を用いて検索を行う方法。
論理和・論理積などのブーリアンモデルの演算を検索の絞り込みに利用する際に用いられる。
研究者や法律・医学等の専門的な実務家など、特定の分野の専門家を対象にした検索システムなどに用いられることが多い。
ＳＱＬのようなデータベースマネージメントシステムで標準的標準的が言語を用いることもあるが、特定の検索エンジン特有の検索言語を用いているシステムも多い。
実現例としてはＩＥＥＥ　Ｘｐｌｏｒｅなどがある。
直接入力
検索のパラメータとなる関連するデータを直接入力する方法。
たとえば特定の画像を入力にして類似した画像を検索するものや、ハミングの入力を受けて関連する音楽クリップを検索するものなどが研究されている。
自然文
検索に関わるユーザインタフェースの研究として古くから研究が行われている。
近年ではＧｏｏ　ラボによって開発された「日本語自然文検索」が大手の検索エンジンとしては比較的珍しい自然文検索を試験的に提供したことで話題を集めた。
文書
文書そのものを入力し、入力した文書と類似する文書を検索する。
Ｑｕｅｒｙ　ｂｙ　Ｅｘａｍｐｌｅ（例示による問い合わせ）と呼ばれることもある。
マルチメディア文書検索では、キーワード検索よりもより一般的に用いられる方法である。
検索アルゴリズム
情報検索に用いられるアルゴリズムは数多く提案されている。
ここでは代表的なものについて概説する。
情報検索アルゴリズムの詳細については情報検索アルゴリズムを参照のこと。
一般に情報検索システムの構築時にはメタデータ生成時に索引を同時に作成し、検索アルゴリズムによる検索結果の評価の際に索引を用いた最適化を行うが、メタデータの生成法や索引の詳細についてはここでは扱わない。
パターンマッチング
検索質問として入力された表現をそのまま含む文書を検索するアルゴリズム。
現在では単純にパターンのみを探すではなく、活用形の変化による同義語のパターンの不一致を解消した検索を行ったりといった拡張がしばしば行われる。
パターンマッチング自体の詳細なアルゴリズムについては文字列探索を参照。
ブーリアンモデル
パターンマッチングの検索に付け加え、メタデータの属性ごとの絞り込み条件を論理和・論理積などによって組み合わせて併用する検索方法。
ベクトル空間モデル
キーワード等を各次元として設定した高次元ベクトル空間を想定し、検索の対象とするデータやユーザによる検索質問に何らかの加工を行いベクトルを生成する。
ベクトル空間上に検索対象となるベクトルを配置し、ベクトル化された検索質問とデータのベクトルの相関量（ベクトル間のコサイン、内積、ユークリッド距離などが用いられる。
）によって検索の対象のデータと検索質問の関係の強さを計算するモデル。
潜在的意味索引付け（潜在的意味分析、ＬＳＩ）
ベクトル空間モデルの応用として考案された検索アルゴリズム。
高次元ベクトル空間を行列として扱い特異値分解を行い、得られた直交低次元ベクトル空間上検索を行う。
単純なベクトル空間モデルでの検索に比べて、同義語が用いられている文書間の関連を反映し、検索の対象のデータの内容的な偏りに影響を受けにくい検索を行うことができるというメリットがある。
機械翻訳（きかいほんやく）とは、ある自然言語を別の自然言語へ機械的に変換する技術をいう。
機械翻訳の概念自体はコンピュータの存在以前より存在するため、機械翻訳と翻訳ソフトは同義ではないが、現在ではほとんど翻訳ソフトとして実装される。
例として、英語の文章を入力するとそれを翻訳した日本語の文章を出力する英和翻訳ソフトウエアなどがある。
自動翻訳ともいう。
近年は統計、人工知能、コンピュータ処理能力、データベース、記憶容量の進歩により急速に成長している分野である。
尚、翻訳方法のもう一つとして、「人力翻訳（人の手による翻訳）」がある。
目次
１　歴史
２　アプローチ
２．１　統計翻訳
３　問題
３．１　語義の多義性
３．２　常識
４　翻訳支援
５　実用性
６　アプリケーション
７　評価
８　関連項目
９　外部リンク
１０　出典
歴史
この節は執筆の途中です　この節は執筆中です。
加筆、訂正して下さる協力者を求めています。
アプローチ
現在広く使われている機械翻訳の原理は次のとおりである。
　言語　Ｘ　で書かれている文を言語　Ｙ　に翻訳する場合：
言語　Ｘ　の文を構文解析する。
得られた構文木を、定められた規則に従って変換し、言語　Ｙ　の構文木を得る。
変換した構文木から言語　Ｙ　の文を生成する。
例として、英語から日本語への翻訳を考える。
　以下のような原文が与えられたとしよう。
”Ｉ　ｈａｖｅ　ａ　ｐｅｎ．”
この文を解析して得られる構文木は次のようになる：
ＥｎｇｌｉｓｈＳｙｎｔａｘＴｒｅｅＳａｍｐｌｅ１．ｐｎｇ
ここで、以下のような辞書を使って英語の単語を日本語の単語に置き換える：
英語　　日本語
Ｉ　　私
ｈａｖｅ　　持っている
ａ　　ー　（空白）
ｐｅｎ　　ペン
構文木は次のようになる：
（Ｓ　（ＮＰ　（ｐｒｏｎ　私））　（ＶＰ　（ｖｅｒｂ　持っている）　（ＮＰ　（ｄｅｔ　ー）　（ｎｏｕｎ　ペン））））
しかしまだ語順が正しくないし、助詞もない。
　ここで構文木に対して以下のような規則を適用して変換をおこなう：
”Ｓ　→　ＮＰ　ＶＰ”　というノードがあれば、それを　”Ｓ　→　ＮＰ　は　ＶＰ”　に変換せよ。
”ＶＰ　→　ｖｅｒｂ　ＮＰ”　というノードがあれば、それを　”ＶＰ　→　ＮＰ　を　ｖｅｒｂ”　に変換せよ。
すると変換された木はこのようになっている：
（Ｓ　（ＮＰ　（ｐｒｏｎ　私））　は　（ＶＰ　（ＮＰ　（ｄｅｔ　ー）　（ｎｏｕｎ　ペン））　を　（ｖｅｒｂ　持っている）））
ここから、以下のような翻訳文を生成できる：
”私はペンを持っている。
”
これは非常に単純な例である。
　実際には英語の　ｈａｖｅ　は複数の語義をもつので、語義の曖昧性解消をしなければ単純に「ｈａｖｅ　→　持っている」という変換をすることはできない。
　また、モダリティの考慮や、照応の解決、敬語の扱い、自然な言いまわしの文の生成など実用的な翻訳ソフトウエアをつくるためには多くのことを考慮に入れる必要がある。
統計翻訳
詳細は「統計翻訳」を参照
計算機の発達によって１９９０年代以降研究が盛んになっているのは統計的な手法を用いた機械翻訳である。
　これは音声認識の分野で用いられていた雑音チャネルモデルを応用したもので、元言語（翻訳元の言語）　ｆ　は目的言語（翻訳後の言語）　ｅ　が雑音のある通信路を通る間に変化してしまったものであると捉え、翻訳とは元言語から目的言語への復号であると考える。
　この時、復号誤りが最も小さくなる翻訳結果　\ｈａｔ｛ｅ｝　は以下の式を満たすことによって得られる。
\ｈａｔ｛ｅ｝　=　\ｍａｔｈｒｍ｛ａｒｇｍａｘ｝＿｛ｅ｝　Ｐ（ｅ|ｆ）
しかし、このままではモデル化が難しいため、ベイズの定理を用いて以下のように変形する。
\ｍａｔｈｒｍ｛ａｒｇｍａｘ｝＿｛ｅ｝　Ｐ（ｅ|ｆ）　=　\ｍａｔｈｒｍ｛ａｒｇｍａｘ｝＿｛ｅ｝　\ｆｒａｃ｛Ｐ（ｅ）Ｐ（ｆ|ｅ）｝｛Ｐ（ｆ）｝　=　\ｍａｔｈｒｍ｛ａｒｇｍａｘ｝＿｛ｅ｝Ｐ（ｅ）Ｐ（ｆ|ｅ）
よって
\ｈａｔ｛ｅ｝　=　\ｍａｔｈｒｍ｛ａｒｇｍａｘ｝＿｛ｅ｝　Ｐ（ｅ）Ｐ（ｆ|ｅ）
ここで　Ｐ（ｅ）　をモデル化したものを言語モデル、Ｐ（ｆ|ｅ）　をモデル化したものを翻訳モデルと呼び、言語モデルは言語としての確からしさを、翻訳モデルは翻訳の確からしさをモデル化していると言える。
そして、これらのモデルから翻訳候補を生成し、最も確率の高い翻訳結果を探索する処理系をデコーダと呼ぶ。
翻訳モデルのみでは目的言語として正しくない文となってしまうため、言語モデルによって目的言語として正しくない文を取り除けると考えられる。
また、言語モデルについての研究は音声認識などの分野において既に研究が行われており、その知見を生かすこともできる。
実際にはパラレルコーパスと呼ばれる文同士の対応がついた２言語間のコーパスを用いてこの確率を推定することになる。
問題
語義の多義性
この節は執筆の途中です　この節は執筆中です。
加筆、訂正して下さる協力者を求めています。
常識
機械による翻訳の困難さのひとつは、それが文法や単語の意味の解析といった論理的処理だけでは解決しない点にもある。
たとえば次の英語の文は、
Ｔｉｍｅ　ｆｌｉｅｓ　ｌｉｋｅ　ａｎ　ａｒｒｏｗ．
普通はこれを「時は矢のように飛び去る」（光陰矢のごとし）と解釈するが、これを「時間蠅は矢を好む」と訳することも可能で、文法的にも破綻がない。
当然、普通は後者は間違いなのであるが、後者を捨て去る判断ができるためには、人には時が素早く過ぎると感じられることがあること、矢は速く飛ぶこと、時間蠅という生き物は存在しなさそうなこと、虫が矢を好むことなどありそうにないこと等の知識が必要である。
極論すれば、正しい翻訳を行うためにはその文がかかわる世界そのものに関するあらゆる知識や感覚が必要になる。
また、ありそうにない時間蠅も、たとえばルイス・キャロルなら存在させるかもしれず、問題はより複雑になる。
翻訳支援
「翻訳支援ツール」および「翻訳メモリ」も参照
いわゆる機械翻訳は「自動翻訳」と「翻訳支援」の２つのまったく異なる方向で用いられる。
自動翻訳では人間の介入は最小限であり、すべてを機械に翻訳させようとする。
これは「翻訳元の言語を理解することができない人」のための技術である。
翻訳支援はプロの翻訳者が翻訳作業を効率的かつ高品質に行うために翻訳ソフトを活用するものである。
これはすでに一部の先進的な翻訳者によって活用されている。
実用性
現実の翻訳は互いの言語の関係によっても大きく異なる。
言語はそれぞれ孤立して存在するものではなく、多かれ少なかれ互いに影響しあって存在する。
特に共通の歴史が長い場合、文法や語彙に共通性、あるいは共通の起源を多く持つことがある。
そのような場合、極端に言えば単語を置き換えるだけでもある程度のレベルの翻訳が可能であるから、機械翻訳もより容易い。
だいたいの意味を知るための概訳については、フランス語、スペイン語、イタリア語などインド・ヨーロッパ語族ロマンス語系諸語間の自動翻訳は比較的順当であり、英語とロマンス語系あるいはゲルマン語系言語との間の自動翻訳も実用レベルに達しているといえる。
日本語からの翻訳の場合、実用のレベルにあるのは日韓自動翻訳である。
日本語と韓国語は膠着語であるという文法的共通性や、漢語からの借用語もあり、自動翻訳の精度は文体にもよるが普通８０％～９０％である。
このため、日韓間では自動翻訳掲示板など実用サイトも存在する。
（外部リンク、ＮＡＶＥＲ日韓自動翻訳掲示板参照）。
日本語の場合助詞や同音異義語が多数存在するために形態素解析の段階で翻訳に困難をきたす。
ゆえに一般に英日翻訳に比べて日英翻訳の能力は低い段階にある　。
英語の語学力のない人が英訳を行い出来上がった英文の評価が出来ない場合、英訳した文を日本語に再変換してみて日本語で意味が通るかどうか確認してみると良い。
翻訳支援の場合、では、特定の分野の翻訳に適したユーザー辞書を作成することにより、翻訳ソフトの訳質は大幅に向上する。
だが一定規模の企業・組織ユーザー以外の、一般ユーザーの小規模な利用シナリオでは、ユーザー辞書の利用効果よりも作成にかかる時間・労力のほうが大きい。
その理由には、辞書作成に技能を要する、ユーザー辞書のコンテンツがない、辞書の相互利用のためのインフラがない、翻訳の量が少ない（規模が少ない・頻度が少ない）といったことが考えられる。
これらの問題を解決するために、ＡＡＭＴ（アジア太平洋機械翻訳協会）がユーザー辞書を共有するための仕様であるＵＰＦを策定した。
その後、２００６年から後継の仕様であるＵＴＸが現在策定中である。
翻訳ソフト（ほんやくソフト）とは、パソコン上で翻訳を行うソフトウェアである。
機械翻訳の項も参照。
目次
１　翻訳ソフトと機械翻訳
２　翻訳ソフトの種類
３　翻訳ソフトの特性
４　代表的な翻訳ソフト
５　関連項目
翻訳ソフトと機械翻訳
現在では機械翻訳（ｍａｃｈｉｎｅ　ｔｒａｎｓｌａｔｉｏｎ）はソフトウェアによって行われ、その意味では「機械翻訳　=　翻訳ソフト」である。
しかし、機械翻訳の概念はコンピュータより以前に存在する。
コンピュータ翻訳と言わずに、機械翻訳というのはそのせいであろう。
しかし、機械翻訳という表現は、人間の主体性が低く、ともすれば「機械が最初から最後まですべて翻訳する」という印象を与えがちである。
これは、「翻訳作業支援ツールとしての翻訳ソフト」の理解の妨げとなることもある。
そのため、機械翻訳という表現を避けて、「翻訳ソフト」と言い換えることを勧める人もいる。
翻訳ソフトの種類
無料から数万円程度の一般消費者向けの製品と、数万円から１０万円前後の業務用製品に大別される。
前者は自動翻訳を主眼に置き、「英語が苦手なユーザー」が「ボタン一つで翻訳」といった手軽さを志向している。
これに対して、後者は専門辞書や辞書の管理機能などが充実しており、翻訳支援に使われる。
翻訳メモリとの連携が可能な製品もある。
対話的翻訳が可能な対訳エディタは、最近は安価な製品にも搭載されるようになったが、上位製品では必須である。
業務用翻訳ソフトは、「それを使えば誰でもプロ並みの翻訳ができる」といったものではない。
業務用翻訳ソフトを「英語が苦手なユーザー」が購入する場合もあるが、業務用翻訳ソフトは専門知識と技能を備えた翻訳者によってのみ、その真価を発揮できる。
翻訳ソフトの特性
翻訳ソフトは、手紙のように非定型的な文章や、ニュースなど新語や固有名詞が多く、多様な話題である文章は苦手である。
専門的な内容であっても、定型的で不特定多数を対象として分かりやすく書かれた文章、つまりマニュアルなどの文章では効果が高い。
適切な専門用語辞書さえあれば、専門性が高ければ高いほどその有用性は高まる。
固有表現抽出（こゆうひょうげんちゅうしゅつ、英：　ｎａｍｅｄ　ｅｎｔｉｔｙ　ｅｘｔｒａｃｔｉｏｎ、ｎａｍｅｄ　ｅｎｔｉｔｙ　ｒｅｃｏｇｎｉｔｉｏｎ）とは、計算機を用いた自然言語処理技術の一つであり、固有名詞（人名、地名など）や日付、時間表現などを抽出する技術である。
情報抽出の一分野であるとされる。
目次
１　目的
２　歴史
３　具体例
４　手法
５　固有表現分類
６　参考文献
７　関連項目
８　外部リンク
目的
新聞記事など現実世界に存在するテキストには大量の固有表現　（Ｎａｍｅｄ　Ｅｎｔｉｔｙ）　が含まれている。
形態素解析などを行なう際、それらの固有表現は辞書に登録されていない場合、未知語として扱われ、解析の誤りを起こす。
そのため、様々な固有表現を辞書に登録する必要があるが、前述の通り、現実のテキストには大量の固有表現が存在し、人手でそれらを登録することは困難である。
この問題を解決するため、計算機によって大量のテキストから固有表現を自動的に抽出する技術が生まれた。
歴史
この節は執筆の途中です　この節は執筆中です。
加筆、訂正して下さる協力者を求めています。
固有表現という概念と固有表現抽出が提唱されたのは、１９９０年頃アメリカ合衆国のＤＡＲＰＡが組織した評価型プロジェクト　ＭＵＣ　（Ｍｅｓｓａｇｅ　Ｕｎｄｅｒｓｔａｎｄｉｎｇ　Ｃｏｎｆｅｒｅｎｃｅ）　においてであるとされる。
日本国内においては情報抽出・情報検索の評価型ワークショップである　ＩＲＥＸ　（Ｉｎｆｏｒｍａｔｉｏｎ　Ｒｅｔｒｉｅｖａｌ　ａｎｄ　Ｅｘｔｒａｃｔｉｏｎ　Ｅｘｅｒｃｉｓｅ）　における情報抽出の共有タスクの一つとして出題された。
自然言語生成（英：　Ｎａｔｕｒａｌ　ｌａｎｇｕａｇｅ　ｇｅｎｅｒａｔｉｏｎ）とは、自然言語処理の一種で知識ベースや論理形式などの機械表現系から自然言語を生成することを言う。
自然言語理解の逆と言われることもある。
自然言語理解が入力文を明確化して機械表現言語を生成するのに対して、自然言語生成は概念を如何にして言葉で表すかについて判断を必要とする。
目次
１　概要
２　応用
３　参考文献
４　外部リンク
概要
テキスト生成プロセスには、たとえば決まり文句の一覧から選ばれた言葉を接続用テキストで繋げるといった単純な処理もある。
これは例えば、占い機械やパーソナライズされたビジネスレターのような領域では十分な文章を生成する。
しかし洗練された自然言語生成システムでは、決まり文句の繰り返しに見えない自然な文章を生成するため、情報の統合と計画のフェーズを必要とする。
典型的なフェーズは次の通りである。
コンテンツ決定
言及する価値がある特徴・属性を決定する。
この段階で使う技法はデータマイニングと関係する。
論述計画
情報提示を全体として構成する。
文の統合
類似の文を統合して、可読性と自然らしさを改善する。
例えば、「次の列車はカレドニア急行です」と「次の列車は午前１０時にアバディーンを発ちます」という文を統合して「午前１０時発の次の列車はカレドニア急行です」とする。
語彙化
概念を単語に置き換える。
参照表現の生成
代名詞などの参照を意味する表現を導入して文の中の単語同士をリンクする。
統語的／形態素的処理
構文解析の逆を行う。
これまでのフェーズで集めた全ての情報を使って、統語論規則と形態論規則を適用し、実際の文を表す文字列を生成する。
正書法処理
大文字小文字や約物の使い分け、フォーマットなどを行う。
応用
自然言語生成の応用の最たる例は、数値などの言語的でないデータをテキスト化された概要に変換するシステムであり、自然言語生成とデータ解析を統合したものである。
例えば、数値予報データから自動的に天気予報の文章を生成するシステムなどがある。
また、変わったところでは、ジョークを自動生成するシステムもある。
光学文字認識（こうがくもじにんしき、英：　Ｏｐｔｉｃａｌ　Ｃｈａｒａｃｔｅｒ　Ｒｅｃｏｇｎｉｔｉｏｎ）は、活字の文書の画像（通常イメージスキャナーで取り込まれる）をコンピュータが編集できる形式（文字コードの列）に変換するソフトウェアである。
一般にＯＣＲと略記される。
ＯＣＲは、人工知能やマシンビジョンの研究分野として始まった。
研究は続けられているが、ＯＣＲの中心はその実装と応用に移っている。
紙に印刷された文書をデジタイズし、よりコンパクトな形で記録するのに必要とされる。
さらに、文字コードに変換することで機械翻訳や音声合成の入力にも使えるようになり、テキストマイニングも可能となる。
研究分野としては、パターン認識、人工知能、コンピュータビジョンが対応する。
（鏡やレンズといった光学技術を使った）光学文字認識と（スキャナーとアルゴリズムによる）デジタル文字認識は本来別の領域と考えられていた。
光学技術として生き残った部分が非常に少ないため、光学文字認識という言葉は現在ではデジタル文字認識を含むものとみなされている。
初期のシステムは特定の書体を読むための「トレーニング」が必要であった（事前にその書体のサンプルを読ませることを意味する）。
現在では、ほとんどの書体を高い識字率で変換することが可能である。
いくつかのシステムでは読み込まれた画像からそれとほぼ同じになるようフォーマットされた出力（例えばワードプロセッサのファイルのようなもの）を生成することが可能であり、中には画像などの文書以外の部分が含まれていても正しく認識するものもある。
目次
１　歴史
２　視覚障害者にとっての重要性
３　ＯＣＲ技術の状況
４　楽譜ＯＣＲ
５　ＯＣＲソフトウェア
６　脚注
７　関連項目
８　外部リンク
歴史
光学文字認識の原点は、電信技術の拡張と視覚障害者が文字を読むための機械の開発という２つの問題にまつわる活動である。
１９１４年エマニュエル・ゴールドバーグ（英語版）は、文字列を読み取り電信符号に変換する機械を開発した［要出典］。
同じころエドマンド・フルニエ・ダルベ（英語版）はオプトフォン（英語版）という携帯型スキャナを開発した。
これを印刷物のページ上ですべらせると、文字の形状によって異なる音を発する。
ゴールドバーグはデータ入力手段としてＯＣＲ技術の開発を続けた。
後に彼は、画像を光電管で読み取り、必要な識別パターンを含むテンプレートと比較することでマッチングを見つけるという技法を提案した。
１９２９年、グスタフ・タウシェク（英語版）も同様のアイデアを思いつき、ドイツでＯＣＲに関する特許を取得した。
アメリカでは１９３３年、ポール・Ｗ・ハンデルが同様のテンプレート・マッチング方式のＯＣＲ技術の特許を取得している（アメリカ合衆国特許第１，９１５，９９３号）。
１９３５年、タウシェクもアメリカで特許を取得した（アメリカ合衆国特許第２，０２６，３２９号）。
１９４９年、米国復員軍人援護局から視覚障害者支援のためという要請を受け、ＲＣＡの技術者らが初期のコンピュータを使ったＯＣＲを研究した。
この研究には、単に活字をコンピュータ内の文字コードに変換するだけでなく、その文字を読み上げるという部分も含まれており、初期の音声合成の研究でもある。
しかし、コストがかかりすぎることが判明し、研究は挫折した。
１９５０年、ＡＦＳＡ（アメリカ国家安全保障局の前身）の暗号解読者デイヴィッド・Ｈ・シェパード（英語版）は、日本のパープル暗号を解読したことで知られるフランク・ロウレットの依頼により、ルイス・トーデラと共に局の手続きの自動化の勧告案作成に取り組んだ。
その中には印刷された文書をコンピュータが処理できる形式に変換する問題も含まれていた。
シェパードはそのようなことをする機械　”Ｇｉｓｍｏ”　を作成することを決め、友人のハーヴェイ・クックと共に自宅で夜や週末を利用して試作に取り組んだ。
１９５３年、シェパードは特許（アメリカ合衆国特許第２，６６３，７５８号）を取得。
Ｇｉｓｍｏは英語のアルファベットのうち２３文字を読み取ることができ、モールス符号を理解し、楽譜を読みとることができ、活字のページを読み上げることができ、タイプされたページを読みとってプリンターで複製することができた。
シェパードはその後　Ｉｎｔｅｌｌｉｇｅｎｔ　Ｍａｃｈｉｎｅｓ　Ｒｅｓｅａｒｃｈ　Ｃｏｒｐｏｒａｔｉｏｎ（英語版）　（ＩＭＲ）　を設立し、世界初のいくつかの商用ＯＣＲシステムを出荷した。
Ｇｉｓｍｏ　も　ＩＭＲ　のシステムも単純な文字マッチングではない画像解析をしていて、いくつかの書体を認識することができた。
Ｇｉｓｍｏ　は画像中の文字の位置を正確に合わせる必要があったが、ＩＭＲシステムではスキャン領域のどこの文字であっても認識でき、実用に耐えるものであった。
最初の商用システムは１９５５年にリーダーズ・ダイジェスト社に納入され、販売報告書をコンピュータに入力するのに使われた。
タイプされた報告書をパンチカードに変換し、それをコンピュータに入力するもので、年間１５００万から２０００万部を売り上げている同社の事務処理を効率化した。
このシステムは後にスミソニアン博物館に無償で提供され展示されている。
２台目のシステムはスタンダード・オイルがカリフォルニア州でクレジットカードの文字を読み取るために使い、他の石油会社もこれに追随した。
ＩＭＲが１９５０年代後半に販売した他のシステムとしては電話会社の請求書読み取り装置やアメリカ空軍のテレタイプ用ページスキャナーなどがある。
ＩＢＭなどは後にシェパードからＯＣＲ特許のライセンス供与を受けている。
１９６５年ごろ、リーダーズ・ダイジェストとＲＣＡは、使われて戻ってきた同誌の広告についているクーポンのシリアル番号を読み取るＯＣＲ装置を共同で開発した。
シリアル番号はＲＣＡのプリンターでＯＣＲーＡフォント（英語版）で印字された。
読み取り装置は　ＲＣＡ　３０１　というコンピュータに直接接続された。
この技術はＴＷＡで航空チケットの読み取りにも使われることとなる。
読み取り装置は毎分１，５００枚の文書を処理でき、正しく読み取れなかった文書は弾かれる。
ＲＣＡはこれを製品化し、保険会社などが採用した。
アメリカ合衆国郵便公社も１９６５年から発明家ジェイコブ・レインボー（英語版）の開発した技術を元にしてＯＣＲマシンを使っている。
ヨーロッパでＯＣＲを最初に採用したのはイギリスの郵便局だった。
イギリスでは１９６５年、郵便貯金に相当するナショナル・ジャイロ（英語版）がＯＣＲを使った自動化を行った。
カナダの郵便局は１９７１年からＯＣＲを使用している。
ＯＣＲは受取人の名前と住所を読み取ってソート（分類）するために使われる。
そして郵便番号に基づいたバーコードを封筒に印刷する。
その後手紙はバーコードにしたがって細かくソートをする。
バーコードが宛名とかぶる可能性があるため（基本的に宛名や住所はどこに書いても良い）、バーコードは紫外線ライトで見える特殊なインクを使用している。
このインクは通常の光ではオレンジ色に見える。
なお、日本では漢字の読み取りが難しいため、１９６８年７月１日に郵便番号が導入され、手書きの数字である郵便番号をＯＣＲシステムで読み取ってソートしていた。
１９９８年に郵便番号の７桁化がなされてからはＯＣＲで読み取った際にアメリカのようにバーコード（ただしこちらは可視光では無色なインクを使用）を印刷するようになった。
視覚障害者にとっての重要性
１９７４年、レイ・カーツワイルはあらゆる書体を読み取れるＯＣＲの開発を行う　Ｋｕｒｚｗｅｉｌ　Ｃｏｍｐｕｔｅｒ　Ｐｒｏｄｕｃｔｓ，　Ｉｎｃ．　を創業。
カーツワイルは、音声合成技術と組合わせればこの技術が視覚障害者にとって最も役立つと考えた。
鍵となる技術はＣＣＤイメージスキャナと音声合成である。
１９７６年１月１３日、製品の完成披露が行われた。
１９７８年、カーツワイルはＯＣＲソフトウェアの販売を開始。
最初の顧客はレクシスネクシスで、ニュースなどの文書をデータベースに入力するのに使った。
２年後、カーツワイルは会社をゼロックスに売却。
後にゼロックスはその部門を　Ｓｃａｎｓｏｆｔ　としてスピンオフさせ、Ｓｃａｎｓｏｆｔ　はニュアンスコミュニケーションズ（英語版）と合併した。
ＯＣＲ技術の状況
１９９０年代中ごろ、アメリカ合衆国エネルギー省　（ＤＯＥ）　は情報科学研究所　（ＩＳＲＩ）　に印刷文書の認識技術育成という使命を与えた。
それにより５年間に渡って　Ａｎｎｕａｌ　Ｔｅｓｔ　ｏｆ　ＯＣＲ　Ａｃｃｕｒａｃｙ　がまとめられた。
ラテン文字の活字文書の正確な認識はほとんど解決済みの問題だが、識字率（文字を正しく認識する確率）は１００％ではなく、間違いの許されない状況では人間が結果を確認する必要がある。
１９世紀および２０世紀初頭の新聞を使った研究によると、単純に文字単位で認識する市販のＯＣＲソフトウェアの識字率は７１％から９８％だった。
手書き文字、特に筆記体の手書き文字認識や文字数の多い言語の文字認識ではまだ研究の余地がある。
文字認識の精度はいくつかの測定法で表され、実際に使用した測定法によって精度は大きく左右される。
例えば、文脈や辞書を使わずに純粋に文字単位で認識する場合、識字率が９９％であっても、単語ベースの誤り率は５％となるかもしれない。
オンライン文字認識は光学文字認識と混同されることがある（手書き文字認識参照）。
ＯＣＲは基本的にオフラインの文字認識であり、純粋に文字の静的な形状を認識する。
一方オンライン文字認識は、文字が書かれる動的な過程を認識する。
例えば、ＰｅｎＰｏｉｎｔ　ＯＳ　やタブレットコンピュータなどがジェスチャーを認識するのもオンライン認識の一種であり、ペンがどういう方向にどれだけ動いたかを認識する。
オンライン手書き文字認識を知的文字認識（英語版）　（ＩＣＲ）　とも呼ぶ。
手書き文字認識システムは近年、商用で成功している分野である。
この技術はＰａｌｍ　ＯＳなどが動作する携帯情報端末で入力手段として採用された。
アップル・ニュートンがこの技術の先駆者である。
これらの機器では筆順や速度や線の方向が入力時に分かるので比較的認識が容易である。
また、ユーザー側も徐々に認識されやすい文字を書くようにトレーニングされるという面もある。
一方、紙に書かれた手書き文字を認識するソフトウェアには上記の利点が無いため、識字率はいまだ十分とは言えない。
きれいに書かれた手書き文字でも識字率は８０％から９０％であり、１ページにつき数十個の認識不能文字が出現することになる。
これは非常に限られた分野でしか実用化できないレベルである。
筆記体文書の認識は研究が盛んであるが、識字率はさらに低い。
筆記体の文字認識の識字率を高めるには、文脈や文法の情報を使わなければならない。
例えば、辞書の単語を認識するのは、手書き原稿の個々の文字を認識するよりも簡単である。
小切手に書かれた数字の列は小さな辞書を使えばいいので識字率を上げることができる。
スキャンしている文書の言語の文法に関する知識があれば、単語が名詞なのか動詞なのかを判別することが可能となり識字率を上げることができる。
手書き文字の形だけでは正確な認識（一般に９８％以上）は不可能といってよい。
ＯＣＲ技術はアドバンストスキャン技術の基盤となっている。
一般に、より複雑な認識問題にはニューラルネットワークを使うことが多く、非線形な変形でも線形な変形でもよく機能する。
文書内の認識が難しい単語や文字列の認識で大いに成功を収めている技法として、人間の文字認識能力を利用したｒｅＣＡＰＴＣＨＡシステムがある。
楽譜ＯＣＲ
詳細は「楽譜ＯＣＲ」を参照
１９７０年代、印刷された楽譜を読み取る研究がＭＩＴなどの研究所で行われた。
その後楽譜の記号を認識する研究が続けられ、商用のソフトウェアは　１９９１年に　”ＭＩＤＩＳＣＡＮ　ｆｏｒ　Ｗｉｎｄｏｗｓ”　（現：ＳｍａｒｔＳｃｏｒｅ（英語版））　がリリースされた。
　なお日本においては１９９５年楽譜ＯＣＲを搭載した楽譜作成ソフトウェアのスコアメーカーが河合楽器製作所にて製造販売されている。
質問応答システム
移動：　案内，　検索
質問応答システム（しつもんおうとうシステム）は、特定の種類の情報に対する質問をユーザから自然言語で受けつけ、その解答を返すようなコンピュータソフトウェアのこと。
解答は文章か、質問に対する直接解答がほとんどである。
　検索エンジンを用いるものや百科辞典などを用いたり、さまざまなデータベースを基にして検索を行う。
　英語のサイトでは　ＡｓｋＪｅｅｖｅｓ　が有名。
基本的な処理の流れは、以下のようになる。
質問文分析（質問文を単語や節など、検索エンジンのクエリに変換する）
検索エンジン（ここではＡＮＤ検索など通常のクエリを投げかけることが多い）
絞込み（取得した文章から、解答部分を抽出する）
結果表示（解答をスコア順に並び替え、表示する）
質問応答は、情報検索、情報抽出、自然言語処理など多数の分野に渡る技術が用いられている。
音声認識（おんせいにんしき，　ｓｐｅｅｃｈ　ｒｅｃｏｇｎｉｔｉｏｎ）は、ヒトの話す音声言語をコンピュータによって解析し、話している内容を文字データとして取り出す処理のこと。
キーボードからの入力に代わる文字入力方法として注目を集めている。
音声認識に関連が深い技術として、あらかじめ記録しておいた音声パターンと比較して個人認証等をおこなう、話者認識がある。
パソコンの場合、文章を入力する用途では音声入力またはディクテーション、アプリケーションの操作は音声操作と呼ばれる。
目次
１　認識技術
１．１　統計的手法
１．２　動的時間伸縮法
１．３　隠れマルコフモデル
２　実際と課題
２．１　性能
３　研究中の技術
３．１　ＭＦＴ
３．２　ＧＳＳ
４　実用例
４．１　Ｗｉｎｄｏｗｓにおける利用
４．２　企業・団体における利用
４．３　その他の利用例
４．４　その他の応用例
５　音声認識ソフトウェア例
５．１　音声認識を応用したゲームソフト例
６　参考文献
７　外部リンク
８　出典
９　関連項目
認識技術
統計的手法
音声認識では、統計的手法が良く用いられている。
これは大量の発話を記録した学習用データから音声の特徴を蓄積し、入力された音声信号と蓄積された特徴とを比較しながら、最も特徴に近い言語系列を認識結果として出力する手法である。
一般に、音声の音響的な特徴と言語的な特徴を分離して扱うことが多い。
音響的な特徴とは、認識対象の音素がそれぞれどのような周波数特性を持っているかを表したもので、音響モデルと呼ばれる。
音響モデルの表現としては、混合正規分布を出力確率とした隠れマルコフモデルが広く用いられている。
言語的な特徴とは、音素の並び方に関する制約を表したもので、言語モデルと呼ばれる。
例えば、「あなた　（ａ　ｎ　ａ　ｔ　ａ）」という発声の直後には、「が　（ｇ　ａ）」や「は　（ｗ　ａ）」などの発声が続く確率が高い、などの制約である。
言語モデルの表現としては、認識対象の言語が大規模な場合（パソコン上での文書作成など）はｎーｇｒａｍが良く用いられ、認識対象の言語が人手で網羅出来る程度に小さい場合（カーナビの音声操作など）は、文脈自由文法が良く用いられる。
動的時間伸縮法
動的時間伸縮法（Ｄｙｎａｍｉｃ　ｔｉｍｅ　ｗａｒｐｉｎｇ、ＤＴＷ）は初期の音声認識手法であるが、隠れマルコフモデルに基づく手法が一般化したため、使われなくなった。
時間または早さの異なる２つの信号シーケンスの間の類似度を測るアルゴリズムである。
例えば、人間の歩行のパターンは、素早く歩いても、ゆっくり歩いても、さらには歩行の画像を早送りしてもスロー再生しても一定のパターンが存在する。
ＤＴＷ　は音声だけでなく動画などの任意の時系列のデータに適用可能である。
音声認識においては、発声速度がどうであっても一定のパターンを検出するために使われていた。
従って、比較のための標準パターンが必要であり、認識できる語彙は限定される。
隠れマルコフモデル
音声信号は、断片的あるいは短時間の定常信号と見ることができ、隠れマルコフモデル（Ｈｉｄｄｅｎ　Ｍａｒｋｏｖ　Ｍｏｄｅｌ、ＨＭＭ）が適用可能である。
すなわち、１０ミリ秒程度の短時間でみた場合、音声信号は近似的に定常過程と見なすことができる。
従って、音声を多くの確率過程のマルコフ連鎖と考えることができる。
また、隠れマルコフモデルによる音声認識は自動的にトレーニングされ、単純で計算量もそれほど多くない。
音声認識について考えられる最も簡単な設定では、隠れマルコフモデルは１０ミリ秒ごとに例えば１３次元程度の実数値ベクトルを出力するだろう。
このベクトルはケプストラム係数から成る。
ケプストラム係数は短時間の信号のフーリエ変換にコサイン変換を使って、その第一（最大）係数を取り出したものである。
隠れマルコフモデルは、それぞれの観測されたベクトルの尤度を与える対角共分散のガウス分布の混合ともいうべき確率分布を持つ傾向がある。
各単語や各音素はそれぞれ独自の出力分布を持つ。
単語列あるいは音素列に関する隠れマルコフモデルは、個々の単語や音素の隠れマルコフモデルを連結したものとなる。
これらが隠れマルコフモデルを使用した音声認識技術の概念である。
音声認識システムにはこれ以外にも様々な技術を使用している。
語彙の多いシステムでは、音素について文脈依存性を考慮する。
また、話者間の違いや録音状況の違いを正規化するために、ケプストラムの正規化が行われる。
他にも話者正規化の試みとして、男女間の正規化のための声道長正規化　（ＶＴＬＮ）　や、より不特定多数の話者に対応するための最尤線形回帰　（ＭＬＬＲ）　がある。
実際と課題
音声認識システムの研究開発にはコンピュータが普及しだした１９７０年代から２１世紀初頭の現在まで、長年にわたって莫大な資金と優秀な人材が投入されてきたが、成功して普及したものはほとんどなく、デジタル技術によって生み出された３次元映像に代表されるアニメーション映画や、動画、静止画、音楽の記録と再生といった技術分野は、その後、大きな産業となっているのと比べれば大きな違いがある。
話者を限定して、「ディクテーション」と呼ばれる事前のトレーニングを行う方式の音声認識システムでは、日本語では理想的な環境下では８０％の認識率が達成できるとされている。
それらのトレーニングを積まない場合６０％が限度である。
語彙を限定してトレーニングを必要としないシステムでは、不特定多数の話者の音声を認識できるが語彙が少ないために利用範囲は限定される。
　同音異義語が少ない欧米系の言語では９０％の認識率があると評価されている　。
個人向けに市販されている音声認識ソフトでは、静かな部屋でユーザーがヘッドセットを使い、単語を区切るなどのいくつかのコツを知っていれば十分実用的な認識率を示す。
ただし屋内であっても背後で大声の会話がなされる環境や、屋外などの騒音のある環境では認識が困難である。
また、個人のレベルで使用することを想定しているため、対応する語彙が限られ業務用語はカバーされていない。
さらに、複数の話者による発声や、音声認識向けと意識していない、例えばインタビューや会議などの発声を認識するのは困難である。
企業向けでは、大規模語彙と複数の不特定話者に対応した会議などの議事録作りに使えるより高価なソフトも販売されており［要出典］、カセットテープやＩＣレコーダの聞き起こしに比べ効率的に作業を行うことができる。
性能
音声認識システムの性能は一般に正確度と速度で表される。
正確度は単語誤り率　（ｗｏｒｄ　ｅｒｒｏｒ　ｒａｔｅ，　ＷＥＲ）　で表され、速度は実時間係数　（ｒｅａｌ　ｔｉｍｅ　ｆａｃｔｏｒ，　ＲＴＦ）で表される。
研究中の技術
ＭＦＴ
話者の音声の特徴量が雑音や特徴分離処理によって歪むと音響モデルとの差が開いて誤認識の元となる。
得られた音声の特徴量に歪みや雑音がどの程度含まれているかを推定し時間軸と周波数軸に対して信頼度をマップとして持たせて、低信頼度の特徴量にはマスクをかけたり、失われた音声を復元する処理に活用するのがミッシング・フィチャー理論（Ｍｉｓｓｉｎｇ　ｆｅａｔｕｒｅ　ｔｈｅｏｒｙ）　である。
ＧＳＳ
ＧＳＳ（Ｇｅｏｍｅｔｒｉｃ　ｓｏｕｒｃｅ　ｓｅｐａｒａｔｉｏｎ）は複数の音源を分離する技術であり、音源間に相関が無ければ複数のマイクからの入力情報によって比較的簡単に音源分離とその位置情報（音源定位）が得られる。
これをＭＦＴの雑音情報として信頼度マップに反映させれば、騒音下や同時発話の状況でもそれほど認識率を落とさずに済む。
実用例
Ｗｉｎｄｏｗｓにおける利用
Ｗｉｎｄｏｗｓ　ＶｉｓｔａとＷｉｎｄｏｗｓ　７では音声認識機能が搭載されており、この機能を使用して、キーボード入力なしにチャットをするなどの操作が可能となっている。
音声認識機能でパソコンを操作するといった利用方法はこれまでにもあったが、日本語の認識率を向上させているほか、マウスやキーボードで行うＷｉｎｄｏｗｓの操作が音声で操作できるようになっている。
企業・団体における利用
企業、病院、自治体では、２００５ー６年頃から次第に次のような実用システムの導入が活発化してきている。
医師向け電子カルテ入力システム
自治体向け議事録作成支援システム
コールセンター向けオペレータ支援・通話内容分析システム
学校向け語学学習アプリケーションでの発音評価システム
その他の利用例
携帯端末（ｉＰｈｏｎｅなど）へのメール文章入力
同時通訳型の機械翻訳、自動通訳
パソコン上での文書作成（口述筆記の自動化）
音声指示による機械操作（カーナビ、電子カルテ等のハンズフリーコンピューティング）
指示を聞き分けるペットロボット（ロボット工学への応用）
音声対話受付案内システム（自動音声応答装置）
裁判員制度での評議における証言内容などの確認（映像と文字の連動）
音声Ｗｅｂアプリケーション　ｗ３ｖｏｉｃｅ　Ｌａｂｏｒａｔｏｒｙ　（音声認識や対話を体験できるＷｅｂサイト）
その他の応用例
「感性制御技術」（Ｓｅｎｓｉｂｉｌｉｔｙ　Ｔｅｃｈｎｏｌｏｇｙ=ＳＴ）などと組み合わせることにより、例えば「ごめんなさい」も口先だけで軽く言った「ごめんなさい」も同じ「ごめんなさい」でしかないが、早口で軽いトーンの「ごめんなさい」は、バカにしていると判断して怒った態度で接したり、ゆっくり丁寧に発音された「ごめんなさい」は、心からの謝辞だと理解して許したりすることが可能となる。
音声合成（おんせいごうせい、Ｓｐｅｅｃｈ　ｓｙｎｔｈｅｓｉｓ）とは、人間の音声を人工的に作り出すことである。
これを行うシステムをスピーチ・シンセサイザー（Ｓｐｅｅｃｈ　ｓｙｎｔｈｅｓｉｚｅｒ）、これにより生成した音声を合成音声（ごうせいおんせい）と呼ぶ。
人工的に人の声を合成するシステムであり、テキスト（文章）を音声に変換できることから、しばしばテキスト読み上げ（ｔｅｘｔーｔｏーｓｐｅｅｃｈ、略してＴＴＳ）システムとも呼ばれる。
また、発音記号を音声に変換するシステムもある。
目次
１　歴史
２　実用例
２．１　テキスト読み上げシステム
２．２　オペレーティングシステムでの音声合成
２．３　インターネットでの音声合成
３　合成技術
３．１　連結的合成
３．２　フォルマント合成（合成音声）
３．３　その他の合成手法
４　日本語音声合成ソフトウェア
５　英語音声合成ソフトウェア
６　音声合成の技術を採用している主な製品
７　関連項目
８　脚注
９　注記
１０　外部リンク
歴史
現代的な電子信号処理が発明されるずっと以前から、音声を合成する試みがなされてきた。
初期の試みとしては、のちに教皇シルウェステル２世となるオーリヤックのジェルベール（１００３年没）、アルベルトゥス・マグヌス（１２８０年没）、ロジャー・ベーコン（１２９４年没）などの人物が音声合成を試みている。
１７７９年にはドイツ人クリスティアン・クラッツェンシュタインは母音　（ａ，　ｅ，　ｉ，　ｏ，　ｕ）　を発声できる機械を製作した。
この流れはふいごを使った機械式音声合成器を作ったオーストリア（ハンガリー）のヴォルフガング・フォン・ケンペレンに引き継がれた。
彼は１７９１年に論文を発表し、その機械について説明している。
この機械は舌と唇をモデル化しており、母音だけでなく子音も発音できた。
１８３７年、チャールズ・ホイートストンはフォン・ケンペレンのデザインを元にしゃべる機械を製作し、１８５７年、Ｍ．　ＦａｂｅｒはＥｕｐｈｏｎｉａを製作した。
ホイートストンの機械は１９２３年Ｐａｇｅｔによって再現されている。
１９３０年代、ベル研究所のホーマー・ダドリー（Ｈｏｍｅｒ　Ｄｕｄｌｅｙ）は通信用の電子式音声分析・音声合成マシンであるヴォコーダー　（Ｖｏｃｏｄｅｒ、Ｖｏｉｃｅ　Ｃｏｄｅｒの略）　を開発した。
その後これを応用し、音声合成部にキーボードを付加した鍵盤演奏型のスピーチ・シンセサイザーであるヴォーダー（ｖｏｄｅｒ）を製作し、ニューヨーク万国博覧会　（１９３９年）に出展した。
その発声は十分理解可能だったと言われる。
１９４０年代、ハスキンズ研究所（Ｈａｓｋｉｎｓ　Ｌａｂｏｒａｔｏｒｉｅｓ）のフランクリン・Ｓ・クーパー（Ｆｒａｎｋｌｉｎ　Ｓ．　Ｃｏｏｐｅｒ）らはＰａｔｔｅｒｎ　ｐｌａｙｂａｃｋという名の機械の開発に取り組み、１９５０年に完成した。
この機械にはいくつかのバージョンがあるが、実際に機能したのは一つだけである。
この機械は、スペクトル形式の音声パターンの図を音に変換するものであった。
アルヴィン・リバーマン（Ａｌｖｉｎ　Ｌｉｂｅｒｍａｎ）らはこれを音声学の研究に利用した。
最初のコンピュータを使った音声合成システムは１９５０年代終盤に開発され、最初のテキスト読み上げシステムは１９６８年に開発されている。
１９６１年、物理学者Ｊｏｈｎ　Ｌａｒｒｙ　Ｋｅｌｌｙ，　Ｊｒ．とＬｏｕｉｓ　Ｇｅｒｓｔｍｅｎはベル研究所にてＩＢＭ　７０４を使って音声合成を行った。
そして『デイジー・ベル』という歌をコンピュータに歌わせた。
友人のジョン・ピアースを訪ねてベル研究所に来ていたアーサー・Ｃ・クラークは、このデモを聴いて感銘を受け、『２００１年宇宙の旅』でＨＡＬ　９０００が歌うクライマックスシーンが生まれた。
初期の電子式スピーチ・シンセサイザーの発声は、ロボット的であまり明瞭ではないものが多かった。
その後の発達により、今日のＴＴＳシステムはむしろ人間の声と区別が付かない場合が少なくない。
（ただし電子式の成功後も、人間型ロボットに発声させるため、機械式音声合成の研究は続けられた。
電子式ではスピーカーの音質に制限されるが、ロボットで人間の体の構造を模倣した機械式音声合成なら、もっと人間に近い発声になると考えられていたからである）。
実用例
音声合成技術は文字を読むことが困難な障害者や、文字が読めない人（幼児、外国人など）に画面読み上げソフト（スクリーンリーダー）として長く利用されてきており、言葉を発することが困難な人が代替手段として利用することも多い。
また、２０００年頃から家電製品の音声ガイダンスや、公共交通機関や防災関係のアナウンス用途として音声合成されたものが広く使用されるようになっている。
これは、人間が発声したものを録音すると、台詞の変更の度にその部分を録音をし直さなければならないが、音声合成であればデータの作成で済むためである。
実際に、鉄道用アナウンスでは、駅が追加されたり名称変更があっても、その箇所のみが変更されている。
また、最近では個人向けのソフトウェアなどにも活用されてきている。
テキスト読み上げシステム
テキスト読み上げシステムは、フロントエンドとバックエンドのふたつの部分からなる。
一般に、フロントエンドは入力したテキストから記号化言語表現　（ｓｙｍｂｏｌｉｃ　ｌｉｎｇｕｉｓｔｉｃ　ｒｅｐｒｅｓｅｎｔａｔｉｏｎ）　を出力する。
バックエンドはフロントエンドで合成された音声の波形を出力する。
音声合成の自然さは、出力される音声がいかに現実の人間の音声に似ているか、明瞭度は聴きやすさ（出力音声の理解しやすさ）で評価される。
フロントエンド
フロントエンドにはふたつの大きな仕事がある。
ひとつはテキストの中の数字や省略表現を読み上げるときの表現に変換することである。
これは、「テキストの正規化」、「プリプロセッシング」、「トークン化」などと呼ばれる。
もうひとつは各単語を発音記号に変換し、テキストを熟語や文節、文などの韻律単位に分割することである。
単語に発音記号を割り当てる処理をテキスト音素（ｔｅｘｔーｔｏーｐｈｏｎｅｍｅ、略してＴＴＰ）変換または書記素音素（ｇｒａｐｈｅｍｅーｔｏーｐｈｏｎｅｍｅ、略してＧＴＰ）変換と呼ぶ。
発音記号と韻律情報を組み合わせて記号化言語表現を作成し、フロントエンドの出力とする。
訳注
この部分は言語によってかなり違いがある。
日本語の場合、わかち書きをしない為、文章を正確に処理するためには単語を分割する作業が必要となる。
バックエンド
フロントエンドの出力結果を元に、より自然な音声にするため韻律などの音声の調整を行い、実際の音声データを出力する。
この処理にて音声の性質が決定されるため、音声合成ソフト独自色が出ることが多い。
また、一般的に「話言葉」を目指す物が多いが、歌声の様な調整を行なう音声合成ソフトもある。
オペレーティングシステムでの音声合成
アップル
１９８４年、アップルコンピュータにＭａｃＩｎＴａｌｋ機能を搭載した。
その後も新しいＯＳバージョンでは音質が改善されている。
また、音声認識も導入しており、これらの機能を統合したＰｌａｉｎＴａｌｋは視覚障害者のためのサポートプログラムであった。
Ｍａｃ　ＯＳ　Ｘ　ｖ１０．４以降にはＶｏｉｃｅＯｖｅｒという音声合成機能になっている。
ＡｍｉｇａＯＳ
１９８５年のＡｍｉｇａＯＳでも音声合成機能が組み込まれていた。
男性と女性の声を選択できる。
ＡｍｉｇａＯＳでは音声合成を仮想デバイスとしていたため、コンソール出力を音声合成にリダイレクトすることも可能であった。
このため、ワープロソフトなど各種アプリケーションで容易に音声合成を利用可能であった。
Ｍｉｃｒｏｓｏｆｔ　Ｗｉｎｄｏｗｓ
Ｗｉｎｄｏｗｓでは、ＳＡＰＩという音声関係のＡＰＩを用意している。
Ｗｉｎｄｏｗｓ　ＸＰではＮａｒｒａｔｏｒという音声合成プログラムが追加されている（英語版）。
コールセンターなどでの音声認識と音声合成のパッケージとしてＭｉｃｒｏｓｏｆｔ　Ｓｐｅｅｃｈ　Ｓｅｒｖｅｒが用意されている。
その他
ＴＩー９９／４Ａには音声合成機能をオプションで追加可能であった。
ＰＣー６００１ｍｋＩＩには音声合成機能が内蔵されていた。
後継のＰＣー６００１ｍｋＩＩＳＲやＰＣー６６０１では歌うことも可能であった。
ＦＭー７／ＦＭー７７シリーズには音声合成ボード　（ＭＢ２２４３７／ＦＭー７７ー４３１）　がオプションとして用意されている。
ＭＺー１５００／２５００／２８６１にはオプションとしてボイスボード（ＭＺー１Ｍ０８）が存在する。
英語での数字などの音声をチップに。
五十音と、いくつかのフレーズを外部チップにサンプリングされＲＯＭとして焼きこまれており、制御によって再生するものである。
インターネットでの音声合成
音声合成マークアップ言語
テキストを音声に変換するためのＸＭＬ準拠のマークアップ言語がいくつかある。
最近ではＳＳＭＬがＷ３Ｃから提案されドラフト状態である。
他にもＳＡＢＬＥ、ＪＳＭＬなどがある。
Ｃａｓｃａｄｉｎｇ　Ｓｔｙｌｅ　Ｓｈｅｅｔｓ　２のサブセットはＡｕｒａｌ　Ｃａｓｃａｄｉｎｇ　Ｓｔｙｌｅ　Ｓｈｅｅｔｓを含んでいる。
音声合成マークアップ言語はＶｏｉｃｅＸＭＬのようなダイアログ・マークアップ言語とは異なる。
ダイアログ・マークアップ言語はテキスト読み上げだけでなく、音声認識などにも対応している。
合成技術
音声波形を生成する主要技術は、大きく連結的合成　（ｃｏｎｃａｔｅｎａｔｉｖｅ　ｓｙｎｔｈｅｓｉｓ）　とフォルマント合成　（ｆｏｒｍａｎｔ　ｓｙｎｔｈｅｓｉｓ）　の２つに分ける事ができる。
連結的合成
連結的合成は、基本的には録音された音声の断片を連結して合成する方法である。
一般に連結的合成は最も自然な合成音声になるといわれているが、発声のバリエーションと波形の断片化の細かさによっては出力音声に欠損が生じ、自然さを損なうことがある。
連結的合成には以下にあげる三種類がある。
単位選択合成　（Ｕｎｉｔ　ｓｅｌｅｃｔｉｏｎ　ｓｙｎｔｈｅｓｉｓ）　
別名としてコーパスベース音声合成方式とも呼ばれる。
大きな音声のデータベース（通常一時間以上の録音された音声から成る）を使用する。
データベースを作成する為には、録音する音声を「音」、「音節」、「形態素」、「単語」、「成句」、「文節」などに分割し、それらを人の手によって検索できるようにインデックスを調整して作成する。
音声合成を行う際には、アルゴリズムに従って最も適した音の組み合わせをデータベースから探し出して合成する。
これにより極めて肉声に近い自然な音声に合成することが可能となる。
しかし、より自然に聞こえる音声を合成するにはデータベースの情報量を増やす必要があり、データサイズが膨大となる問題も発生する。
Ｄｉｐｈｏｎｅ合成　（Ｄｉｐｈｏｎｅ　ｓｙｎｔｈｅｓｉｓ）
音声ライブラリにターゲットとする言語のＤｉｐｈｏｎｅ（音と音のつながり部分）を全て持ち、それを使用して合成する。
Ｄｉｐｈｏｎｅの個数はその言語の音素配列論で決まっている。
（スペイン語なら８００、ドイツ語なら２５００のＤｉｐｈｏｎｅを持つ。
）Ｄｉｐｈｏｎｅ合成では、各Ｄｉｐｈｏｎｅの音声がひとつだけデータベースに格納されている。
実行時にはＤｉｐｈｏｎｅを並べたものに線形予測分析法（ＰＳＯＬＡ、ＭＢＲＯＬＡなど）のようなデジタル信号処理技法を施して韻律を作る。
できあがった音声は単位選択合成に比較すると音質が劣るが、フォルマント合成よりは自然な音質になる。
しかし、Ｄｉｐｈｏｎｅ合成は結合部の欠陥が目立ち、フォルマント合成のようなロボット的な発生になってしまう問題がある。
そのため商用では徐々に利用が減っているが、フリーソフトウェアや研究用としては使われ続けている。
分野限定合成　（Ｄｏｍａｉｎーｓｐｅｃｉｆｉｃ　ｓｙｎｔｈｅｓｉｓ）
録音された単語や文節を連結して音声を合成する。
これは特定分野のテキスト読み上げに使われる。
例えば乗り換え案内の放送や天気予報などである。
これは実装が簡単なので商用にも長年使われてきた。
例えば、しゃべる時計や電卓などである。
この方式は分野を限定しているので自然に聞こえる音声を合成するのが簡単である。
しかし、汎用ではないので、利用は限定される。
内部のデータベースにある単語や文節しか話せないため、内容が登録されている音声によって限定される。
また、例えばフランス語のリエゾンなど、前後の単語との関係で発音が変わる場合を再現するのが難しい。
この場合、文脈を考慮して合成する必要がある。
フォルマント合成（合成音声）
フォルマント合成は録音された人間の音声は使用せず、基底周波数、音色、雑音レベルなどのパラメータを調整して波形を作り、人工的な音声を作る。
合成された音声はロボット的に聞こえる音声になるため、人間の音声と間違えることはない。
フォルマント合成は連結的合成と比べ次の様な特徴も持っている。
音の欠損がないので、高速に発声させても明瞭に聞き取れる。
このため高速さを要求されるテキスト読み上げにはよく使われている。
連結的合成のような音声データベースを必要としないので、データのサイズが小さくなる。
出力音声を容易に変化させることができるので、イントネーションや音色を自由に変えることが出来る。
上記の様な特徴のため、組み込みシステムでもよく使われ、フォルマント合成の例として、１９７０年代末にテキサス・インスツルメンツが発売した玩具Ｓｐｅａｋ　＆　Ｓｐｅｌｌ、セガの１９８０年代のいくつかのアーケードゲームがある（Ａｓｔｒｏ　Ｂｌａｓｔｅｒ、Ｓｐａｃｅ　Ｆｕｒｙ、Ｓｔａｒ　Ｔｒｅｋ：　Ｓｔｒａｔｅｇｉｃ　Ｏｐｅｒａｔｉｏｎｓ　Ｓｉｍｕｌａｔｏｒなど）。
これらのイントネーションの再現は非常によく、リアルタイムのテキスト読み上げインタフェースでの実現はこれからである。
その他の合成手法
Ａｒｔｉｃｕｌａｔｏｒｙ　ｓｙｎｔｈｅｓｉｓ
最近まで純粋に学術的研究として使われてきた手法である。
それは人間の声道部分の構造を研究してそこで起こっていることを人工的に再現するものである。
最近になってその成果が商用の音声合成でも使えるレベルになってきた。
ＮｅＸＴで使われていたシステムはカナダのカルガリー大学の研究チームがスピンオフして作ったＴｒｉｌｌｉｕｍ　Ｓｏｕｎｄ　Ｒｅｓｅａｒｃｈ　Ｉｎｃ．が開発したものである。
Ｔｒｉｌｌｉｕｍはこれをフリーなｇｎｕｓｐｅｅｃｈとして公開しており、ＧＮＵ　ｓａｖａｎｎａｈ　ｓｉｔｅで入手可能である。
Ｈｙｂｒｉｄ　ｓｙｎｔｈｅｓｉｓ
フォルマントと連結的合成を組み合わせたもので、音の欠損をなるべく少なくしたものである。
ＨＭＭーｂａｓｅｄ　ｓｙｎｔｈｅｓｉｓ
隠れマルコフモデル（ＨＭＭ）に基づいた合成である。
このシステムでは、周波数スペクトル、基本周波数、持続時間（韻律）がＨＭＭによって同時にモデル化される。
音声波形はＨＭＭ自体が最尤法に基づいて生成する。
Ｓｉｎｅｗａｖｅ　ｓｙｎｔｈｅｓｉｓ
フォルマントを純粋な正弦波の合成によって構成する技法である。
