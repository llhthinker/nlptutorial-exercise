In_IN computational_JJ linguistics_NNS ,_, word-sense_JJ disambiguation_NN -LRB-_-LRB- WSD_NN -RRB-_-RRB- is_VBZ an_DT open_JJ problem_NN of_IN natural_JJ language_NN processing_NN ,_, which_WDT governs_VBZ the_DT process_NN of_IN identifying_VBG which_WDT sense_NN of_IN a_DT word_NN -LRB-_-LRB- i.e._FW meaning_NN -RRB-_-RRB- is_VBZ used_VBN in_IN a_DT sentence_NN ,_, when_WRB the_DT word_NN has_VBZ multiple_JJ meanings_NNS -LRB-_-LRB- polysemy_NN -RRB-_-RRB- ._.
The_DT solution_NN to_TO this_DT problem_NN impacts_VBZ other_JJ computer-related_JJ writing_NN ,_, such_JJ as_IN discourse_NN ,_, improving_VBG relevance_NN of_IN search_NN engines_NNS ,_, anaphora_NN resolution_NN ,_, coherence_NN ,_, inference_NN et_FW cetera_FW ._.
Research_NNP has_VBZ progressed_VBN steadily_RB to_TO the_DT point_NN where_WRB WSD_NNP systems_NNS achieve_VBP sufficiently_RB high_JJ levels_NNS of_IN accuracy_NN on_IN a_DT variety_NN of_IN word_NN types_NNS and_CC ambiguities_NNS ._.
A_DT rich_JJ variety_NN of_IN techniques_NNS have_VBP been_VBN researched_VBN ,_, from_IN dictionary-based_JJ methods_NNS that_WDT use_VBP the_DT knowledge_NN encoded_VBN in_IN lexical_JJ resources_NNS ,_, to_TO supervised_JJ machine_NN learning_NN methods_NNS in_IN which_WDT a_DT classifier_NN is_VBZ trained_VBN for_IN each_DT distinct_JJ word_NN on_IN a_DT corpus_NN of_IN manually_RB sense-annotated_JJ examples_NNS ,_, to_TO completely_RB unsupervised_JJ methods_NNS that_WDT cluster_VBP occurrences_NNS of_IN words_NNS ,_, thereby_RB inducing_VBG word_NN senses_NNS ._.
Among_IN these_DT ,_, supervised_JJ learning_NN approaches_NNS have_VBP been_VBN the_DT most_RBS successful_JJ algorithms_NNS to_TO date_NN ._.
Current_JJ accuracy_NN is_VBZ difficult_JJ to_TO state_NN without_IN a_DT host_NN of_IN caveats_NNS ._.
In_IN English_NNP ,_, accuracy_NN at_IN the_DT coarse-grained_JJ -LRB-_-LRB- homograph_JJ -RRB-_-RRB- level_NN is_VBZ routinely_RB above_IN 90_CD %_NN ,_, with_IN some_DT methods_NNS on_IN particular_JJ homographs_NNS achieving_VBG over_IN 96_CD %_NN ._.
On_IN finer-grained_JJ sense_NN distinctions_NNS ,_, top_JJ accuracies_NNS from_IN 59.1_CD %_NN to_TO 69.0_CD %_NN have_VBP been_VBN reported_VBN in_IN recent_JJ evaluation_NN exercises_NNS -LRB-_-LRB- SemEval-2007_NN ,_, Senseval-2_NN -RRB-_-RRB- ,_, where_WRB the_DT baseline_NN accuracy_NN of_IN the_DT simplest_JJS possible_JJ algorithm_NN of_IN always_RB choosing_VBG the_DT most_RBS frequent_JJ sense_NN was_VBD 51.4_CD %_NN and_CC 57_CD %_NN ,_, respectively_RB ._.
WSD_NN task_NN has_VBZ two_CD variants_NNS :_: ``_`` lexical_JJ sample_NN ''_'' and_CC ``_`` all_DT words_NNS ''_'' task_NN ._.
The_DT former_JJ comprises_VBZ disambiguating_VBG the_DT occurrences_NNS of_IN a_DT small_JJ sample_NN of_IN target_NN words_NNS which_WDT were_VBD previously_RB selected_VBN ,_, while_IN in_IN the_DT latter_JJ all_PDT the_DT words_NNS in_IN a_DT piece_NN of_IN running_VBG text_NN need_VBP to_TO be_VB disambiguated_VBN ._.
The_DT latter_NN is_VBZ deemed_VBN a_DT more_RBR realistic_JJ form_NN of_IN evaluation_NN ,_, but_CC the_DT corpus_NN is_VBZ more_RBR expensive_JJ to_TO produce_VB because_IN human_JJ annotators_NNS have_VBP to_TO read_VB the_DT definitions_NNS for_IN each_DT word_NN in_IN the_DT sequence_NN every_DT time_NN they_PRP need_VBP to_TO make_VB a_DT tagging_NN judgement_NN ,_, rather_RB than_IN once_RB for_IN a_DT block_NN of_IN instances_NNS for_IN the_DT same_JJ target_NN word_NN ._.
To_TO give_VB a_DT hint_NN how_WRB all_PDT this_DT works_NNS ,_, consider_VB two_CD examples_NNS of_IN the_DT distinct_JJ senses_NNS that_WDT exist_VBP for_IN the_DT -LRB-_-LRB- written_VBN -RRB-_-RRB- word_NN ``_`` bass_NN ''_'' :_: a_DT type_NN of_IN fish_NN tones_NNS of_IN low_JJ frequency_NN and_CC the_DT sentences_NNS :_: I_PRP went_VBD fishing_NN for_IN some_DT sea_NN bass_NN ._.
The_DT bass_NN line_NN of_IN the_DT song_NN is_VBZ too_RB weak_JJ ._.
To_TO a_DT human_JJ ,_, it_PRP is_VBZ obvious_JJ that_IN the_DT first_JJ sentence_NN is_VBZ using_VBG the_DT word_NN ``_`` bass_NN -LRB-_-LRB- fish_NN -RRB-_-RRB- ''_'' ,_, as_IN in_IN the_DT former_JJ sense_NN above_IN and_CC in_IN the_DT second_JJ sentence_NN ,_, the_DT word_NN ``_`` bass_NN -LRB-_-LRB- instrument_NN -RRB-_-RRB- ''_'' is_VBZ being_VBG used_VBN as_IN in_IN the_DT latter_JJ sense_NN below_IN ._.
Developing_VBG algorithms_NNS to_TO replicate_VB this_DT human_JJ ability_NN can_MD often_RB be_VB a_DT difficult_JJ task_NN ,_, as_IN is_VBZ further_RBR exemplified_VBN by_IN the_DT implicit_JJ equivocation_NN between_IN ``_`` bass_NN -LRB-_-LRB- sound_NN -RRB-_-RRB- ''_'' and_CC ``_`` bass_NN ''_'' -LRB-_-LRB- musical_JJ instrument_NN -RRB-_-RRB- ._.
History_NN WSD_NN was_VBD first_RB formulated_VBN as_IN a_DT distinct_JJ computational_JJ task_NN during_IN the_DT early_JJ days_NNS of_IN machine_NN translation_NN in_IN the_DT 1940s_CD ,_, making_VBG it_PRP one_CD of_IN the_DT oldest_JJS problems_NNS in_IN computational_JJ linguistics_NNS ._.
Warren_NNP Weaver_NNP ,_, in_IN his_PRP$ famous_JJ 1949_CD memorandum_NN on_IN translation_NN ,_, first_RB introduced_VBD the_DT problem_NN in_IN a_DT computational_JJ context_NN ._.
Early_JJ researchers_NNS understood_VBD the_DT significance_NN and_CC difficulty_NN of_IN WSD_NNP well_RB ._.
In_IN fact_NN ,_, Bar-Hillel_NNP -LRB-_-LRB- 1960_CD -RRB-_-RRB- used_VBD the_DT above_JJ example_NN to_TO argue_VB that_IN WSD_NNP could_MD not_RB be_VB solved_VBN by_IN ``_`` electronic_JJ computer_NN ''_'' because_IN of_IN the_DT need_NN in_IN general_JJ to_TO model_VB all_DT world_NN knowledge_NN ._.
In_IN the_DT 1970s_NNS ,_, WSD_NNP was_VBD a_DT subtask_NN of_IN semantic_JJ interpretation_NN systems_NNS developed_VBD within_IN the_DT field_NN of_IN artificial_JJ intelligence_NN ,_, but_CC since_IN WSD_NNP systems_NNS were_VBD largely_RB rule-based_JJ and_CC hand-coded_JJ they_PRP were_VBD prone_JJ to_TO a_DT knowledge_NN acquisition_NN bottleneck_NN ._.
By_IN the_DT 1980s_CD large-scale_JJ lexical_JJ resources_NNS ,_, such_JJ as_IN the_DT Oxford_NNP Advanced_NNP Learner_NNP 's_POS Dictionary_NNP of_IN Current_NNP English_NNP -LRB-_-LRB- OALD_NNP -RRB-_-RRB- ,_, became_VBD available_JJ :_: hand-coding_NN was_VBD replaced_VBN with_IN knowledge_NN automatically_RB extracted_VBN from_IN these_DT resources_NNS ,_, but_CC disambiguation_NN was_VBD still_RB knowledge-based_JJ or_CC dictionary-based_JJ ._.
In_IN the_DT 1990s_CD ,_, the_DT statistical_JJ revolution_NN swept_VBD through_IN computational_JJ linguistics_NNS ,_, and_CC WSD_NNP became_VBD a_DT paradigm_NN problem_NN on_IN which_WDT to_TO apply_VB supervised_JJ machine_NN learning_NN techniques_NNS ._.
The_DT 2000s_NNS saw_VBD supervised_JJ techniques_NNS reach_VBP a_DT plateau_NN in_IN accuracy_NN ,_, and_CC so_RB attention_NN has_VBZ shifted_VBN to_TO coarser-grained_JJ senses_NNS ,_, domain_NN adaptation_NN ,_, semi-supervised_JJ and_CC unsupervised_JJ corpus-based_JJ systems_NNS ,_, combinations_NNS of_IN different_JJ methods_NNS ,_, and_CC the_DT return_NN of_IN knowledge-based_JJ systems_NNS via_IN graph-based_JJ methods_NNS ._.
Still_RB ,_, supervised_JJ systems_NNS continue_VBP to_TO perform_VB best_RB ._.
Difficulties_NNS Differences_NNS between_IN dictionaries_NNS One_CD problem_NN with_IN word_NN sense_NN disambiguation_NN is_VBZ deciding_VBG what_WP the_DT senses_NNS are_VBP ._.
In_IN cases_NNS like_IN the_DT word_NN bass_NN above_IN ,_, at_IN least_JJS some_DT senses_NNS are_VBP obviously_RB different_JJ ._.
In_IN other_JJ cases_NNS ,_, however_RB ,_, the_DT different_JJ senses_NNS can_MD be_VB closely_RB related_JJ -LRB-_-LRB- one_CD meaning_NN being_VBG a_DT metaphorical_JJ or_CC metonymic_JJ extension_NN of_IN another_DT -RRB-_-RRB- ,_, and_CC in_IN such_JJ cases_NNS division_NN of_IN words_NNS into_IN senses_NNS becomes_VBZ much_RB more_RBR difficult_JJ ._.
Different_JJ dictionaries_NNS and_CC thesauruses_NNS will_MD provide_VB different_JJ divisions_NNS of_IN words_NNS into_IN senses_NNS ._.
One_CD solution_NN some_DT researchers_NNS have_VBP used_VBN is_VBZ to_TO choose_VB a_DT particular_JJ dictionary_NN ,_, and_CC just_RB use_VB its_PRP$ set_NN of_IN senses_NNS ._.
Generally_RB ,_, however_RB ,_, research_NN results_NNS using_VBG broad_JJ distinctions_NNS in_IN senses_NNS have_VBP been_VBN much_RB better_RBR than_IN those_DT using_VBG narrow_JJ ones_NNS ._.
However_RB ,_, given_VBN the_DT lack_NN of_IN a_DT full-fledged_JJ coarse-grained_JJ sense_NN inventory_NN ,_, most_JJS researchers_NNS continue_VBP to_TO work_VB on_IN fine-grained_JJ WSD_NN ._.
Most_JJS research_NN in_IN the_DT field_NN of_IN WSD_NN is_VBZ performed_VBN by_IN using_VBG WordNet_NNP as_IN a_DT reference_NN sense_NN inventory_NN for_IN English_NNP ._.
WordNet_NNP is_VBZ a_DT computational_JJ lexicon_NN that_WDT encodes_VBZ concepts_NNS as_IN synonym_NN sets_NNS -LRB-_-LRB- e.g._FW the_DT concept_NN of_IN car_NN is_VBZ encoded_VBN as_IN -LCB-_-LRB- car_NN ,_, auto_NN ,_, automobile_NN ,_, machine_NN ,_, motorcar_NN -RCB-_-RRB- -RRB-_-RRB- ._.
Other_JJ resources_NNS used_VBN for_IN disambiguation_NN purposes_NNS include_VBP Roget_NNP 's_POS Thesaurus_NNP and_CC Wikipedia_NNP ._.
Part-of-speech_JJ tagging_NN In_IN any_DT real_JJ test_NN ,_, part-of-speech_JJ tagging_NN and_CC sense_NN tagging_NN are_VBP very_RB closely_RB related_JJ with_IN each_DT potentially_RB making_VBG constraints_NNS to_TO the_DT other_JJ ._.
And_CC the_DT question_NN whether_IN these_DT tasks_NNS should_MD be_VB kept_VBN together_RB or_CC decoupled_VBN is_VBZ still_RB not_RB unanimously_RB resolved_VBN ,_, but_CC recently_RB scientists_NNS incline_VBP to_TO test_VB these_DT things_NNS separately_RB -LRB-_-LRB- e.g._FW in_IN the_DT Senseval\/SemEval_JJ competitions_NNS parts_NNS of_IN speech_NN are_VBP provided_VBN as_IN input_NN for_IN the_DT text_NN to_TO disambiguate_NN -RRB-_-RRB- ._.
It_PRP is_VBZ instructive_JJ to_TO compare_VB the_DT word_NN sense_NN disambiguation_NN problem_NN with_IN the_DT problem_NN of_IN part-of-speech_JJ tagging_NN ._.
Both_DT involve_VBP disambiguating_VBG or_CC tagging_VBG with_IN words_NNS ,_, be_VB it_PRP with_IN senses_NNS or_CC parts_NNS of_IN speech_NN ._.
However_RB ,_, algorithms_NNS used_VBN for_IN one_CD do_VBP not_RB tend_VB to_TO work_VB well_RB for_IN the_DT other_JJ ,_, mainly_RB because_IN the_DT part_NN of_IN speech_NN of_IN a_DT word_NN is_VBZ primarily_RB determined_VBN by_IN the_DT immediately_RB adjacent_JJ one_CD to_TO three_CD words_NNS ,_, whereas_IN the_DT sense_NN of_IN a_DT word_NN may_MD be_VB determined_VBN by_IN words_NNS further_RB away_RB ._.
The_DT success_NN rate_NN for_IN part-of-speech_JJ tagging_NN algorithms_NNS is_VBZ at_IN present_JJ much_RB higher_JJR than_IN that_DT for_IN WSD_NNP ,_, state-of-the_JJ art_NN being_VBG around_IN 95_CD %_NN accuracy_NN or_CC better_JJR ,_, as_IN compared_VBN to_TO less_JJR than_IN 75_CD %_NN accuracy_NN in_IN word_NN sense_NN disambiguation_NN with_IN supervised_JJ learning_NN ._.
These_DT figures_NNS are_VBP typical_JJ for_IN English_NNP ,_, and_CC may_MD be_VB very_RB different_JJ from_IN those_DT for_IN other_JJ languages_NNS ._.
Inter-judge_JJ variance_NN Another_DT problem_NN is_VBZ inter-judge_JJ variance_NN ._.
WSD_NN systems_NNS are_VBP normally_RB tested_VBN by_IN having_VBG their_PRP$ results_NNS on_IN a_DT task_NN compared_VBN against_IN those_DT of_IN a_DT human_JJ ._.
However_RB ,_, while_IN it_PRP is_VBZ relatively_RB easy_JJ to_TO assign_VB parts_NNS of_IN speech_NN to_TO text_NN ,_, training_NN people_NNS to_TO tag_VB senses_NNS is_VBZ far_RB more_RBR difficult_JJ ._.
While_IN users_NNS can_MD memorize_VB all_DT of_IN the_DT possible_JJ parts_NNS of_IN speech_NN a_DT word_NN can_MD take_VB ,_, it_PRP is_VBZ often_RB impossible_JJ for_IN individuals_NNS to_TO memorize_VB all_DT of_IN the_DT senses_NNS a_DT word_NN can_MD take_VB ._.
Moreover_RB ,_, humans_NNS do_VBP not_RB agree_VB on_IN the_DT task_NN at_IN hand_NN --_: give_VB a_DT list_NN of_IN senses_NNS and_CC sentences_NNS ,_, and_CC humans_NNS will_MD not_RB always_RB agree_VB on_IN which_WDT word_NN belongs_VBZ in_IN which_WDT sense_NN ._.
Thus_RB ,_, a_DT computer_NN can_MD not_RB be_VB expected_VBN to_TO give_VB better_JJR performance_NN on_IN such_PDT a_DT task_NN than_IN a_DT human_JJ -LRB-_-LRB- indeed_RB ,_, since_IN the_DT human_JJ serves_VBZ as_IN the_DT standard_NN ,_, the_DT computer_NN being_VBG better_RBR than_IN the_DT human_JJ is_VBZ incoherent_JJ -RRB-_-RRB- ,_, -LRB-_-LRB- citation_NN needed_VBN -RRB-_-RRB- so_IN the_DT human_JJ performance_NN serves_VBZ as_IN an_DT upper_JJ bound_VBN ._.
Human_JJ performance_NN ,_, however_RB ,_, is_VBZ much_RB better_JJR on_IN coarse-grained_JJ than_IN fine-grained_JJ distinctions_NNS ,_, so_RB this_DT again_RB is_VBZ why_WRB research_NN on_IN coarse-grained_JJ distinctions_NNS has_VBZ been_VBN put_VBN to_TO test_VB in_IN recent_JJ WSD_NN evaluation_NN exercises_NNS ._.
Common_JJ sense_NN Some_DT AI_NNP researchers_NNS like_IN Douglas_NNP Lenat_NNP argue_VBP that_IN one_PRP can_MD not_RB parse_VB meanings_NNS from_IN words_NNS without_IN some_DT form_NN of_IN common_JJ sense_NN ontology_NN ._.
For_IN example_NN ,_, comparing_VBG these_DT two_CD sentences_NNS :_: ``_`` Jill_NNP and_CC Mary_NNP are_VBP sisters_NNS ._. ''_''
--_: -LRB-_-LRB- they_PRP are_VBP sisters_NNS of_IN each_DT other_JJ -RRB-_-RRB- ._.
``_`` Jill_NNP and_CC Mary_NNP are_VBP mothers_NNS ._. ''_''
--_: -LRB-_-LRB- each_DT is_VBZ independently_RB a_DT mother_NN -RRB-_-RRB- ._.
To_TO properly_RB identify_VB senses_NNS of_IN words_NNS one_PRP must_MD know_VB common_JJ sense_NN facts_NNS ._.
Moreover_RB ,_, sometimes_RB the_DT common_JJ sense_NN is_VBZ needed_VBN to_TO disambiguate_VB such_JJ words_NNS like_IN pronouns_NNS in_IN case_NN of_IN having_VBG anaphoras_NNS or_CC cataphoras_NNS in_IN the_DT text_NN ._.
Sense_NN inventory_NN and_CC algorithms_NNS '_POS task-dependency_NN A_NN task-independent_JJ sense_NN inventory_NN is_VBZ not_RB a_DT coherent_JJ concept_NN :_: each_DT task_NN requires_VBZ its_PRP$ own_JJ division_NN of_IN word_NN meaning_NN into_IN senses_NNS relevant_JJ to_TO the_DT task_NN ._.
For_IN example_NN ,_, the_DT ambiguity_NN of_IN `_`` mouse_NN '_'' -LRB-_-LRB- animal_NN or_CC device_NN -RRB-_-RRB- is_VBZ not_RB relevant_JJ in_IN English-French_JJ machine_NN translation_NN ,_, but_CC is_VBZ relevant_JJ in_IN information_NN retrieval_NN ._.
The_DT opposite_NN is_VBZ true_JJ of_IN `_`` river_NN '_'' ,_, which_WDT requires_VBZ a_DT choice_NN in_IN French_JJ -LRB-_-LRB- fleuve_JJ `_`` flows_NNS into_IN the_DT sea_NN '_'' ,_, or_CC rivière_NN `_`` flows_VBZ into_IN a_DT river_NN '_'' -RRB-_-RRB- ._.
Also_RB ,_, completely_RB different_JJ algorithms_NNS might_MD be_VB required_VBN by_IN different_JJ applications_NNS ._.
In_IN machine_NN translation_NN ,_, the_DT problem_NN takes_VBZ the_DT form_NN of_IN target_NN word_NN selection_NN ._.
Here_RB the_DT ``_`` senses_NNS ''_'' are_VBP words_NNS in_IN the_DT target_NN language_NN ,_, which_WDT often_RB correspond_VBP to_TO significant_JJ meaning_NN distinctions_NNS in_IN the_DT source_NN language_NN -LRB-_-LRB- bank_NN could_MD translate_VB to_TO French_JJ banque_NN `_`` financial_JJ bank_NN '_'' or_CC rive_JJ `_`` edge_NN of_IN river_NN '_'' -RRB-_-RRB- ._.
In_IN information_NN retrieval_NN ,_, a_DT sense_NN inventory_NN is_VBZ not_RB necessarily_RB required_VBN ,_, because_IN it_PRP is_VBZ enough_JJ to_TO know_VB that_IN a_DT word_NN is_VBZ used_VBN in_IN the_DT same_JJ sense_NN in_IN the_DT query_NN and_CC a_DT retrieved_VBN document_NN ;_: what_WDT sense_NN that_WDT is_VBZ ,_, is_VBZ unimportant_JJ ._.
Discreteness_NN of_IN senses_NNS Finally_RB ,_, the_DT very_JJ notion_NN of_IN ``_`` word_NN sense_NN ''_'' is_VBZ slippery_JJ and_CC controversial_JJ ._.
Most_JJS people_NNS can_MD agree_VB in_IN distinctions_NNS at_IN the_DT coarse-grained_JJ homograph_NN level_NN -LRB-_-LRB- e.g._FW ,_, pen_NN as_IN writing_VBG instrument_NN or_CC enclosure_NN -RRB-_-RRB- ,_, but_CC go_VBP down_RB one_CD level_NN to_TO fine-grained_JJ polysemy_NN ,_, and_CC disagreements_NNS arise_VBP ._.
For_IN example_NN ,_, in_IN Senseval-2_NN ,_, which_WDT used_VBD fine-grained_JJ sense_NN distinctions_NNS ,_, human_JJ annotators_NNS agreed_VBD in_IN only_RB 85_CD %_NN of_IN word_NN occurrences_NNS ._.
Word_NN meaning_NN is_VBZ in_IN principle_NN infinitely_RB variable_JJ and_CC context_NN sensitive_JJ ._.
It_PRP does_VBZ not_RB divide_VB up_RP easily_RB into_IN distinct_JJ or_CC discrete_JJ sub-meanings_NNS ._.
Lexicographers_NNS frequently_RB discover_VBP in_FW corpora_FW loose_JJ and_CC overlapping_JJ word_NN meanings_NNS ,_, and_CC standard_JJ or_CC conventional_JJ meanings_NNS extended_VBN ,_, modulated_VBN ,_, and_CC exploited_VBD in_IN a_DT bewildering_JJ variety_NN of_IN ways_NNS ._.
The_DT art_NN of_IN lexicography_NN is_VBZ to_TO generalize_VB from_IN the_DT corpus_NN to_TO definitions_NNS that_WDT evoke_VBP and_CC explain_VBP the_DT full_JJ range_NN of_IN meaning_NN of_IN a_DT word_NN ,_, making_VBG it_PRP seem_VB like_IN words_NNS are_VBP well-behaved_JJ semantically_RB ._.
However_RB ,_, it_PRP is_VBZ not_RB at_IN all_DT clear_JJ if_IN these_DT same_JJ meaning_NN distinctions_NNS are_VBP applicable_JJ in_IN computational_JJ applications_NNS ,_, as_IN the_DT decisions_NNS of_IN lexicographers_NNS are_VBP usually_RB driven_VBN by_IN other_JJ considerations_NNS ._.
Recently_RB ,_, a_DT task_NN --_: named_VBN lexical_JJ substitution_NN --_: has_VBZ been_VBN proposed_VBN as_IN a_DT possible_JJ solution_NN to_TO the_DT sense_NN discreteness_NN problem_NN ._.
The_DT task_NN consists_VBZ of_IN providing_VBG a_DT substitute_NN for_IN a_DT word_NN in_IN context_NN that_WDT preserves_VBZ the_DT meaning_NN of_IN the_DT original_JJ word_NN -LRB-_-LRB- potentially_RB ,_, substitutes_NNS can_MD be_VB chosen_VBN from_IN the_DT full_JJ lexicon_NN of_IN the_DT target_NN language_NN ,_, thus_RB overcoming_VBG discreteness_NN -RRB-_-RRB- ._.
Approaches_NNS and_CC methods_NNS As_IN in_IN all_DT natural_JJ language_NN processing_NN ,_, there_EX are_VBP two_CD main_JJ approaches_NNS to_TO WSD_NNP --_: deep_JJ approaches_NNS and_CC shallow_JJ approaches_NNS ._.
Deep_JJ approaches_NNS presume_VBP access_NN to_TO a_DT comprehensive_JJ body_NN of_IN world_NN knowledge_NN ._.
Knowledge_NN ,_, such_JJ as_IN ``_`` you_PRP can_MD go_VB fishing_NN for_IN a_DT type_NN of_IN fish_NN ,_, but_CC not_RB for_IN low_JJ frequency_NN sounds_NNS ''_'' and_CC ``_`` songs_NNS have_VBP low_JJ frequency_NN sounds_NNS as_IN parts_NNS ,_, but_CC not_RB types_NNS of_IN fish_NN ''_'' ,_, is_VBZ then_RB used_VBN to_TO determine_VB in_IN which_WDT sense_NN the_DT word_NN is_VBZ used_VBN ._.
These_DT approaches_NNS are_VBP not_RB very_RB successful_JJ in_IN practice_NN ,_, mainly_RB because_IN such_PDT a_DT body_NN of_IN knowledge_NN does_VBZ not_RB exist_VB in_IN a_DT computer-readable_JJ format_NN ,_, outside_IN of_IN very_RB limited_JJ domains_NNS ._.
However_RB ,_, if_IN such_JJ knowledge_NN did_VBD exist_VB ,_, then_RB deep_JJ approaches_NNS would_MD be_VB much_RB more_RBR accurate_JJ than_IN the_DT shallow_JJ approaches_NNS ._.
-LRB-_-LRB- citation_NN needed_VBN -RRB-_-RRB- Also_RB ,_, there_EX is_VBZ a_DT long_JJ tradition_NN in_IN computational_JJ linguistics_NNS ,_, of_IN trying_VBG such_JJ approaches_NNS in_IN terms_NNS of_IN coded_VBN knowledge_NN and_CC in_IN some_DT cases_NNS ,_, it_PRP is_VBZ hard_JJ to_TO say_VB clearly_RB whether_IN the_DT knowledge_NN involved_VBN is_VBZ linguistic_JJ or_CC world_NN knowledge_NN ._.
The_DT first_JJ attempt_NN was_VBD that_IN by_IN Margaret_NNP Masterman_NNP and_CC her_PRP$ colleagues_NNS ,_, at_IN the_DT Cambridge_NNP Language_NNP Research_NNP Unit_NNP in_IN England_NNP ,_, in_IN the_DT 1950s_CD ._.
This_DT attempt_NN used_VBN as_IN data_NNS a_DT punched-card_JJ version_NN of_IN Roget_NNP 's_POS Thesaurus_NNP and_CC its_PRP$ numbered_VBN ``_`` heads_NNS ''_'' ,_, as_IN an_DT indicator_NN of_IN topics_NNS and_CC looked_VBD for_IN repetitions_NNS in_IN text_NN ,_, using_VBG a_DT set_VBN intersection_NN algorithm_NN ._.
It_PRP was_VBD not_RB very_RB successful_JJ ,_, but_CC had_VBD strong_JJ relationships_NNS to_TO later_RB work_VB ,_, especially_RB Yarowsky_NNP 's_POS machine_NN learning_NN optimisation_NN of_IN a_DT thesaurus_NN method_NN in_IN the_DT 1990s_CD ._.
Shallow_JJ approaches_NNS do_VBP n't_RB try_VB to_TO understand_VB the_DT text_NN ._.
They_PRP just_RB consider_VBP the_DT surrounding_JJ words_NNS ,_, using_VBG information_NN such_JJ as_IN ``_`` if_IN bass_NN has_VBZ words_NNS sea_NN or_CC fishing_NN nearby_RB ,_, it_PRP probably_RB is_VBZ in_IN the_DT fish_NN sense_NN ;_: if_IN bass_NN has_VBZ the_DT words_NNS music_NN or_CC song_NN nearby_RB ,_, it_PRP is_VBZ probably_RB in_IN the_DT music_NN sense_NN ._. ''_''
These_DT rules_NNS can_MD be_VB automatically_RB derived_VBN by_IN the_DT computer_NN ,_, using_VBG a_DT training_NN corpus_NN of_IN words_NNS tagged_VBN with_IN their_PRP$ word_NN senses_NNS ._.
This_DT approach_NN ,_, while_IN theoretically_RB not_RB as_RB powerful_JJ as_IN deep_JJ approaches_NNS ,_, gives_VBZ superior_JJ results_NNS in_IN practice_NN ,_, due_JJ to_TO the_DT computer_NN 's_POS limited_JJ world_NN knowledge_NN ._.
However_RB ,_, it_PRP can_MD be_VB confused_VBN by_IN sentences_NNS like_IN The_DT dogs_NNS bark_VBP at_IN the_DT tree_NN which_WDT contains_VBZ the_DT word_NN bark_NN near_IN both_CC tree_NN and_CC dogs_NNS ._.
There_EX are_VBP four_CD conventional_JJ approaches_NNS to_TO WSD_NNP :_: Dictionary_NNP -_: and_CC knowledge-based_JJ methods_NNS :_: These_DT rely_VBP primarily_RB on_IN dictionaries_NNS ,_, thesauri_NNS ,_, and_CC lexical_JJ knowledge_NN bases_NNS ,_, without_IN using_VBG any_DT corpus_NN evidence_NN ._.
Supervised_VBN methods_NNS :_: These_DT make_VBP use_NN of_IN sense-annotated_JJ corpora_NN to_TO train_VB from_IN ._.
Semi-supervised_JJ or_CC minimally_RB supervised_JJ methods_NNS :_: These_DT make_VBP use_NN of_IN a_DT secondary_JJ source_NN of_IN knowledge_NN such_JJ as_IN a_DT small_JJ annotated_JJ corpus_NN as_IN seed_NN data_NNS in_IN a_DT bootstrapping_NN process_NN ,_, or_CC a_DT word-aligned_JJ bilingual_JJ corpus_NN ._.
Unsupervised_JJ methods_NNS :_: These_DT eschew_NN -LRB-_-LRB- almost_RB -RRB-_-RRB- completely_RB external_JJ information_NN and_CC work_NN directly_RB from_IN raw_JJ unannotated_JJ corpora_NN ._.
These_DT methods_NNS are_VBP also_RB known_VBN under_IN the_DT name_NN of_IN word_NN sense_NN discrimination_NN ._.
Almost_RB all_DT these_DT approaches_NNS normally_RB work_VBP by_IN defining_VBG a_DT window_NN of_IN n_NN content_NN words_NNS around_IN each_DT word_NN to_TO be_VB disambiguated_VBN in_IN the_DT corpus_NN ,_, and_CC statistically_RB analyzing_VBG those_DT n_NN surrounding_VBG words_NNS ._.
Two_CD shallow_JJ approaches_NNS used_VBN to_TO train_VB and_CC then_RB disambiguate_NN are_VBP Naïve_NNP Bayes_NNP classifiers_NNS and_CC decision_NN trees_NNS ._.
In_IN recent_JJ research_NN ,_, kernel-based_JJ methods_NNS such_JJ as_IN support_NN vector_NN machines_NNS have_VBP shown_VBN superior_JJ performance_NN in_IN supervised_JJ learning_NN ._.
Graph-based_JJ approaches_NNS have_VBP also_RB gained_VBN much_JJ attention_NN from_IN the_DT research_NN community_NN ,_, and_CC currently_RB achieve_VBP performance_NN close_RB to_TO the_DT state_NN of_IN the_DT art_NN ._.
Dictionary_NNP -_: and_CC knowledge-based_JJ methods_NNS The_DT Lesk_NNP algorithm_NN is_VBZ the_DT seminal_JJ dictionary-based_JJ method_NN ._.
It_PRP is_VBZ based_VBN on_IN the_DT hypothesis_NN that_IN words_NNS used_VBN together_RB in_IN text_NN are_VBP related_JJ to_TO each_DT other_JJ and_CC that_IN the_DT relation_NN can_MD be_VB observed_VBN in_IN the_DT definitions_NNS of_IN the_DT words_NNS and_CC their_PRP$ senses_NNS ._.
Two_CD -LRB-_-LRB- or_CC more_JJR -RRB-_-RRB- words_NNS are_VBP disambiguated_VBN by_IN finding_VBG the_DT pair_NN of_IN dictionary_NN senses_NNS with_IN the_DT greatest_JJS word_NN overlap_VBP in_IN their_PRP$ dictionary_NN definitions_NNS ._.
For_IN example_NN ,_, when_WRB disambiguating_VBG the_DT words_NNS in_IN ``_`` pine_VB cone_NN ''_'' ,_, the_DT definitions_NNS of_IN the_DT appropriate_JJ senses_NNS both_DT include_VBP the_DT words_NNS evergreen_NN and_CC tree_NN -LRB-_-LRB- at_IN least_JJS in_IN one_CD dictionary_NN -RRB-_-RRB- ._.
An_DT alternative_NN to_TO the_DT use_NN of_IN the_DT definitions_NNS is_VBZ to_TO consider_VB general_JJ word-sense_NN relatedness_NN and_CC to_TO compute_VB the_DT semantic_JJ similarity_NN of_IN each_DT pair_NN of_IN word_NN senses_NNS based_VBN on_IN a_DT given_VBN lexical_JJ knowledge_NN base_NN such_JJ as_IN WordNet_NNP ._.
Graph-based_JJ methods_NNS reminiscent_JJ of_IN spreading_NN activation_NN research_NN of_IN the_DT early_JJ days_NNS of_IN AI_NN research_NN have_VBP been_VBN applied_VBN with_IN some_DT success_NN ._.
More_RBR complex_JJ graph-based_JJ approaches_NNS have_VBP been_VBN shown_VBN to_TO perform_VB almost_RB as_RB well_RB as_IN supervised_JJ methods_NNS or_CC even_RB outperforming_VBG them_PRP on_IN specific_JJ domains_NNS ._.
Recently_RB ,_, it_PRP has_VBZ been_VBN reported_VBN that_IN simple_JJ graph_NN connectivity_NN measures_NNS ,_, such_JJ as_IN degree_NN ,_, perform_VB state-of-the-art_JJ WSD_NN in_IN the_DT presence_NN of_IN a_DT sufficiently_RB rich_JJ lexical_JJ knowledge_NN base_NN ._.
Also_RB ,_, automatically_RB transferring_VBG knowledge_NN in_IN the_DT form_NN of_IN semantic_JJ relations_NNS from_IN Wikipedia_NNP to_TO WordNet_NNP has_VBZ been_VBN shown_VBN to_TO boost_VB simple_JJ knowledge-based_JJ methods_NNS ,_, enabling_VBG them_PRP to_TO rival_VB the_DT best_JJS supervised_VBN systems_NNS and_CC even_RB outperform_VB them_PRP in_IN a_DT domain-specific_JJ setting_NN ._.
The_DT use_NN of_IN selectional_JJ preferences_NNS -LRB-_-LRB- or_CC selectional_JJ restrictions_NNS -RRB-_-RRB- is_VBZ also_RB useful_JJ ,_, for_IN example_NN ,_, knowing_VBG that_IN one_CD typically_RB cooks_NNS food_NN ,_, one_PRP can_MD disambiguate_VB the_DT word_NN bass_NN in_IN ``_`` I_PRP am_VBP cooking_JJ basses_NNS ''_'' -LRB-_-LRB- i.e._FW ,_, it_PRP 's_VBZ not_RB a_DT musical_JJ instrument_NN -RRB-_-RRB- ._.
Supervised_VBN methods_NNS Supervised_VBD methods_NNS are_VBP based_VBN on_IN the_DT assumption_NN that_IN the_DT context_NN can_MD provide_VB enough_JJ evidence_NN on_IN its_PRP$ own_JJ to_TO disambiguate_VB words_NNS -LRB-_-LRB- hence_RB ,_, world_NN knowledge_NN and_CC reasoning_NN are_VBP deemed_VBN unnecessary_JJ -RRB-_-RRB- ._.
Probably_RB every_DT machine_NN learning_VBG algorithm_NN going_NN has_VBZ been_VBN applied_VBN to_TO WSD_NNP ,_, including_VBG associated_VBN techniques_NNS such_JJ as_IN feature_NN selection_NN ,_, parameter_NN optimization_NN ,_, and_CC ensemble_NN learning_NN ._.
Support_NN Vector_NNP Machines_NNP and_CC memory-based_JJ learning_NN have_VBP been_VBN shown_VBN to_TO be_VB the_DT most_RBS successful_JJ approaches_NNS ,_, to_TO date_NN ,_, probably_RB because_IN they_PRP can_MD cope_VB with_IN the_DT high-dimensionality_NN of_IN the_DT feature_NN space_NN ._.
However_RB ,_, these_DT supervised_JJ methods_NNS are_VBP subject_JJ to_TO a_DT new_JJ knowledge_NN acquisition_NN bottleneck_NN since_IN they_PRP rely_VBP on_IN substantial_JJ amounts_NNS of_IN manually_RB sense-tagged_JJ corpora_NN for_IN training_NN ,_, which_WDT are_VBP laborious_JJ and_CC expensive_JJ to_TO create_VB ._.
Semi-supervised_JJ methods_NNS Because_IN of_IN the_DT lack_NN of_IN training_NN data_NNS ,_, many_JJ word_NN sense_NN disambiguation_NN algorithms_NNS use_VBP semi-supervised_JJ learning_NN ,_, which_WDT allows_VBZ both_CC labeled_JJ and_CC unlabeled_JJ data_NNS ._.
The_DT Yarowsky_NNP algorithm_NN was_VBD an_DT early_JJ example_NN of_IN such_PDT an_DT algorithm_NN ._.
It_PRP uses_VBZ the_DT `_`` One_CD sense_NN per_IN collocation_NN '_'' and_CC the_DT `_`` One_CD sense_NN per_IN discourse_NN '_'' properties_NNS of_IN human_JJ languages_NNS for_IN word_NN sense_NN disambiguation_NN ._.
From_IN observation_NN ,_, words_NNS tend_VBP to_TO exhibit_VB only_RB one_CD sense_NN in_IN most_JJS given_VBN discourse_NN and_CC in_IN a_DT given_VBN collocation_NN ._.
The_DT bootstrapping_VBG approach_NN starts_VBZ from_IN a_DT small_JJ amount_NN of_IN seed_NN data_NNS for_IN each_DT word_NN :_: either_CC manually_RB tagged_VBN training_NN examples_NNS or_CC a_DT small_JJ number_NN of_IN surefire_JJ decision_NN rules_NNS -LRB-_-LRB- e.g._FW ,_, `_`` play_VB '_'' in_IN the_DT context_NN of_IN `_`` bass_NN '_'' almost_RB always_RB indicates_VBZ the_DT musical_JJ instrument_NN -RRB-_-RRB- ._.
The_DT seeds_NNS are_VBP used_VBN to_TO train_VB an_DT initial_JJ classifier_NN ,_, using_VBG any_DT supervised_JJ method_NN ._.
This_DT classifier_NN is_VBZ then_RB used_VBN on_IN the_DT untagged_JJ portion_NN of_IN the_DT corpus_NN to_TO extract_VB a_DT larger_JJR training_NN set_NN ,_, in_IN which_WDT only_RB the_DT most_RBS confident_JJ classifications_NNS are_VBP included_VBN ._.
The_DT process_NN repeats_NNS ,_, each_DT new_JJ classifier_NN being_VBG trained_VBN on_IN a_DT successively_RB larger_JJR training_NN corpus_NN ,_, until_IN the_DT whole_JJ corpus_NN is_VBZ consumed_VBN ,_, or_CC until_IN a_DT given_VBN maximum_NN number_NN of_IN iterations_NNS is_VBZ reached_VBN ._.
Other_JJ semi-supervised_JJ techniques_NNS use_VBP large_JJ quantities_NNS of_IN untagged_JJ corpora_NN to_TO provide_VB co-occurrence_NN information_NN that_WDT supplements_VBZ the_DT tagged_VBN corpora_NN ._.
These_DT techniques_NNS have_VBP the_DT potential_NN to_TO help_VB in_IN the_DT adaptation_NN of_IN supervised_JJ models_NNS to_TO different_JJ domains_NNS ._.
Also_RB ,_, an_DT ambiguous_JJ word_NN in_IN one_CD language_NN is_VBZ often_RB translated_VBN into_IN different_JJ words_NNS in_IN a_DT second_JJ language_NN depending_VBG on_IN the_DT sense_NN of_IN the_DT word_NN ._.
Word-aligned_JJ bilingual_JJ corpora_NN have_VBP been_VBN used_VBN to_TO infer_VB cross-lingual_JJ sense_NN distinctions_NNS ,_, a_DT kind_NN of_IN semi-supervised_JJ system_NN ._.
Unsupervised_JJ methods_NNS Main_NNP article_NN :_: Word_NN sense_NN induction_NN Unsupervised_JJ learning_NN is_VBZ the_DT greatest_JJS challenge_NN for_IN WSD_NNP researchers_NNS ._.
The_DT underlying_JJ assumption_NN is_VBZ that_IN similar_JJ senses_NNS occur_VBP in_IN similar_JJ contexts_NNS ,_, and_CC thus_RB senses_NNS can_MD be_VB induced_VBN from_IN text_NN by_IN clustering_NN word_NN occurrences_NNS using_VBG some_DT measure_NN of_IN similarity_NN of_IN context_NN ,_, a_DT task_NN referred_VBN to_TO as_IN word_NN sense_NN induction_NN or_CC discrimination_NN ._.
Then_RB ,_, new_JJ occurrences_NNS of_IN the_DT word_NN can_MD be_VB classified_VBN into_IN the_DT closest_JJS induced_VBN clusters\/senses_NNS ._.
Performance_NNP has_VBZ been_VBN lower_JJR than_IN other_JJ methods_NNS ,_, above_RB ,_, but_CC comparisons_NNS are_VBP difficult_JJ since_IN senses_NNS induced_VBN must_MD be_VB mapped_VBN to_TO a_DT known_JJ dictionary_NN of_IN word_NN senses_NNS ._.
If_IN a_DT mapping_NN to_TO a_DT set_NN of_IN dictionary_NN senses_NNS is_VBZ not_RB desired_VBN ,_, cluster-based_JJ evaluations_NNS -LRB-_-LRB- including_VBG measures_NNS of_IN entropy_NN and_CC purity_NN -RRB-_-RRB- can_MD be_VB performed_VBN ._.
Alternatively_RB ,_, word_NN sense_NN induction_NN methods_NNS can_MD be_VB tested_VBN and_CC compared_VBN within_IN an_DT application_NN ._.
For_IN instance_NN ,_, it_PRP has_VBZ been_VBN shown_VBN that_IN word_NN sense_NN induction_NN improves_VBZ Web_NN search_NN result_NN clustering_NN by_IN increasing_VBG the_DT quality_NN of_IN result_NN clusters_NNS and_CC the_DT degree_NN diversification_NN of_IN result_NN lists_NNS ._.
It_PRP is_VBZ hoped_VBN that_IN unsupervised_JJ learning_NN will_MD overcome_VB the_DT knowledge_NN acquisition_NN bottleneck_NN because_IN they_PRP are_VBP not_RB dependent_JJ on_IN manual_JJ effort_NN ._.
Other_JJ approaches_NNS Other_JJ approaches_NNS may_MD vary_VB differently_RB in_IN their_PRP$ methods_NNS :_: Identification_NN of_IN dominant_JJ word_NN senses_NNS ;_: Domain-driven_JJ disambiguation_NN ;_: WSD_NNP using_VBG Cross-Lingual_JJ Evidence_NN ._.
Local_JJ impediments_NNS and_CC summary_NN The_DT knowledge_NN acquisition_NN bottleneck_NN is_VBZ perhaps_RB the_DT major_JJ impediment_NN to_TO solving_VBG the_DT WSD_NN problem_NN ._.
Unsupervised_JJ methods_NNS rely_VBP on_IN knowledge_NN about_IN word_NN senses_NNS ,_, which_WDT is_VBZ barely_RB formulated_VBN in_IN dictionaries_NNS and_CC lexical_JJ databases_NNS ._.
Supervised_VBN methods_NNS depend_VBP crucially_RB on_IN the_DT existence_NN of_IN manually_RB annotated_JJ examples_NNS for_IN every_DT word_NN sense_NN ,_, a_DT requisite_JJ that_WDT can_MD so_RB far_RB be_VB met_VBN only_RB for_IN a_DT handful_NN of_IN words_NNS for_IN testing_NN purposes_NNS ,_, as_IN it_PRP is_VBZ done_VBN in_IN the_DT Senseval_JJ exercises_NNS ._.
Therefore_RB ,_, one_CD of_IN the_DT most_RBS promising_JJ trends_NNS in_IN WSD_NN research_NN is_VBZ using_VBG the_DT largest_JJS corpus_NN ever_RB accessible_JJ ,_, the_DT World_NNP Wide_NN Web_NN ,_, to_TO acquire_VB lexical_JJ information_NN automatically_RB ._.
WSD_NNP has_VBZ been_VBN traditionally_RB understood_VBN as_IN an_DT intermediate_JJ language_NN engineering_NN technology_NN which_WDT could_MD improve_VB applications_NNS such_JJ as_IN information_NN retrieval_NN -LRB-_-LRB- IR_NN -RRB-_-RRB- ._.
In_IN this_DT case_NN ,_, however_RB ,_, the_DT reverse_NN is_VBZ also_RB true_JJ :_: Web_NN search_NN engines_NNS implement_VBP simple_JJ and_CC robust_JJ IR_NN techniques_NNS that_WDT can_MD be_VB successfully_RB used_VBN when_WRB mining_VBG the_DT Web_NN for_IN information_NN to_TO be_VB employed_VBN in_IN WSD_NNP ._.
Therefore_RB ,_, the_DT lack_NN of_IN training_NN data_NNS provoked_VBD appearing_VBG some_DT new_JJ algorithms_NNS and_CC techniques_NNS described_VBN here_RB :_: Main_NNP article_NN :_: Automatic_NNP Acquisition_NNP of_IN Sense-Tagged_NNP Corpora_NNP External_NNP knowledge_NN sources_NNS Knowledge_NN is_VBZ a_DT fundamental_JJ component_NN of_IN WSD_NN ._.
Knowledge_NN sources_NNS provide_VBP data_NNS which_WDT are_VBP essential_JJ to_TO associate_VB senses_NNS with_IN words_NNS ._.
They_PRP can_MD vary_VB from_IN corpora_NN of_IN texts_NNS ,_, either_CC unlabeled_JJ or_CC annotated_JJ with_IN word_NN senses_NNS ,_, to_TO machine-readable_JJ dictionaries_NNS ,_, thesauri_NNS ,_, glossaries_NNS ,_, ontologies_NNS ,_, etc._FW ._.
They_PRP can_MD be_VB classified_VBN as_IN follows_VBZ :_: Structured_VBN :_: Thesauri_NNP Machine-readable_JJ dictionaries_NNS -LRB-_-LRB- MRDs_NNS -RRB-_-RRB- Ontologies_NNP Unstructured_NNP :_: Corpora_NNP :_: raw_JJ corpora_NN and_CC sense-annotated_JJ corpora_NN Collocation_NNP resources_NNS Other_JJ resources_NNS -LRB-_-LRB- such_JJ as_IN word_NN frequency_NN lists_NNS ,_, stoplists_NNS ,_, domain_NN labels_NNS ,_, etc._NN -RRB-_-RRB- Evaluation_NN Comparing_VBG and_CC evaluating_VBG different_JJ WSD_NN systems_NNS is_VBZ extremely_RB difﬁcult_JJ ,_, because_IN of_IN the_DT different_JJ test_NN sets_NNS ,_, sense_NN inventories_NNS ,_, and_CC knowledge_NN resources_NNS adopted_VBN ._.
Before_IN the_DT organization_NN of_IN speciﬁc_JJ evaluation_NN campaigns_NNS most_JJS systems_NNS were_VBD assessed_VBN on_IN in-house_NN ,_, often_RB small-scale_JJ ,_, data_NNS sets_NNS ._.
In_IN order_NN to_TO test_VB one_PRP 's_POS algorithm_NN ,_, developers_NNS should_MD spend_VB their_PRP$ time_NN to_TO annotate_VB all_DT word_NN occurrences_NNS ._.
And_CC comparing_VBG methods_NNS even_RB on_IN the_DT same_JJ corpus_NN is_VBZ not_RB eligible_JJ if_IN there_EX is_VBZ different_JJ sense_NN inventories_NNS ._.
In_IN order_NN to_TO define_VB common_JJ evaluation_NN datasets_NNS and_CC procedures_NNS ,_, public_JJ evaluation_NN campaigns_NNS have_VBP been_VBN organized_VBN ._.
Senseval_JJ -LRB-_-LRB- now_RB renamed_VBN SemEval_NNP -RRB-_-RRB- is_VBZ an_DT international_JJ word_NN sense_NN disambiguation_NN competition_NN ,_, held_VBD every_DT three_CD years_NNS since_IN 1998_CD :_: Senseval-1_NN -LRB-_-LRB- 1998_CD -RRB-_-RRB- ,_, Senseval-2_NN -LRB-_-LRB- 2001_CD -RRB-_-RRB- ,_, Senseval-3_NN -LRB-_-LRB- 2004_CD -RRB-_-RRB- ,_, and_CC its_PRP$ successor_NN ,_, SemEval_NN -LRB-_-LRB- 2007_CD -RRB-_-RRB- ._.
The_DT objective_NN of_IN the_DT competition_NN is_VBZ to_TO organize_VB different_JJ lectures_VBZ ,_, preparing_VBG and_CC hand-annotating_JJ corpus_NN for_IN testing_NN systems_NNS ,_, perform_VB a_DT comparative_JJ evaluation_NN of_IN WSD_NN systems_NNS in_IN several_JJ kinds_NNS of_IN tasks_NNS ,_, including_VBG all-words_NNS and_CC lexical_JJ sample_NN WSD_NN for_IN different_JJ languages_NNS ,_, and_CC ,_, more_RBR recently_RB ,_, new_JJ tasks_NNS such_JJ as_IN semantic_JJ role_NN labeling_NN ,_, gloss_VBP WSD_NNP ,_, lexical_JJ substitution_NN ,_, etc._NN ._.
The_DT systems_NNS submitted_VBN for_IN evaluation_NN to_TO these_DT competitions_NNS usually_RB integrate_VBP different_JJ techniques_NNS and_CC often_RB combine_VBP supervised_JJ and_CC knowledge-based_JJ methods_NNS -LRB-_-LRB- especially_RB for_IN avoiding_VBG bad_JJ performance_NN in_IN lack_NN of_IN training_NN examples_NNS -RRB-_-RRB- ._.
Task_NNP Design_NNP Choices_NNPS Sense_NN Inventories_NNS ._.
During_IN the_DT first_JJ Senseval_JJ workshop_NN the_DT HECTOR_NN sense_NN inventory_NN was_VBD adopted_VBN ._.
The_DT reason_NN for_IN adopting_VBG a_DT previously_RB unknown_JJ sense_NN inventory_NN was_VBD mainly_RB to_TO avoid_VB the_DT use_NN of_IN popular_JJ fine-grained_JJ word_NN senses_NNS -LRB-_-LRB- such_JJ as_IN WordNet_NNP -RRB-_-RRB- ,_, which_WDT could_MD make_VB the_DT experiments_NNS unfair_JJ or_CC biased_VBN ._.
However_RB ,_, given_VBN the_DT lack_NN of_IN coverage_NN of_IN such_JJ inventories_NNS ,_, since_IN the_DT second_JJ Senseval_JJ workshop_NN the_DT WordNet_NNP sense_NN inventory_NN has_VBZ been_VBN adopted_VBN ._.
A_DT set_NN of_IN testing_NN words_NNS ._.
Comparison_NN of_IN methods_NNS can_MD be_VB divided_VBN in_IN 2_CD groups_NNS by_IN amount_NN of_IN words_NNS to_TO test_VB ._.
The_DT difference_NN consists_VBZ in_IN the_DT amount_NN of_IN analysis_NN and_CC processing_NN :_: all-words_JJ task_NN implies_VBZ disambiguating_VBG all_PDT the_DT words_NNS of_IN the_DT text_NN lexical_JJ sample_NN consists_VBZ in_IN disambiguating_VBG some_DT previously_RB chosen_VBN target_NN words_NNS ._.
It_PRP is_VBZ assumed_VBN that_IN the_DT former_JJ one_CD is_VBZ more_RBR realistic_JJ evaluation_NN ,_, although_IN with_IN very_RB laborious_JJ testing_NN of_IN results_NNS ._.
Initially_RB only_RB the_DT latter_NN was_VBD used_VBN in_IN evaluation_NN but_CC later_RB the_DT former_JJ was_VBD included_VBN ._.
Lexical_JJ sample_NN organizers_NNS had_VBD to_TO choose_VB samples_NNS on_IN which_WDT the_DT systems_NNS were_VBD to_TO be_VB tested_VBN ._.
A_DT criticism_NN of_IN earlier_JJR forays_NNS into_IN lexical-sample_JJ WSD_NN evaluation_NN is_VBZ that_IN the_DT lexical_JJ sample_NN had_VBD been_VBN chosen_VBN according_VBG to_TO the_DT whim_NN of_IN the_DT experimenter_NN -LRB-_-LRB- or_CC ,_, to_TO coincide_VB with_IN earlier_JJR experimenters_NNS '_POS selections_NNS -RRB-_-RRB- ._.
For_IN English_NNP Senseval_NNP ,_, a_DT sampling_NN frame_NN was_VBD devised_VBN in_IN which_WDT words_NNS were_VBD classified_VBN according_VBG to_TO their_PRP$ frequency_NN -LRB-_-LRB- in_IN the_DT BNC_NN -RRB-_-RRB- and_CC their_PRP$ polysemy_NN level_NN -LRB-_-LRB- in_IN WordNet_NNP -RRB-_-RRB- ._.
Also_RB ,_, inclusion_NN POS-tagging_NN problem_NN was_VBD a_DT matter_NN of_IN discussion_NN and_CC it_PRP was_VBD decided_VBN that_IN samples_NNS should_MD be_VB words_NNS with_IN known_JJ part_NN of_IN speech_NN and_CC some_DT indeterminants_NNS -LRB-_-LRB- for_IN ex_FW ._.
15_CD noun_NN tasks_NNS ,_, 13_CD verb_NN tasks_NNS ,_, 8_CD adjectives_NNS ,_, and_CC 5_CD indeterminates_NNS -RRB-_-RRB- ._.
Baselines_NNS ._.
For_IN comparison_NN purposes_NNS ,_, known_VBN ,_, yet_RB simple_JJ ,_, algorithms_NNS named_VBD baselines_NNS are_VBP used_VBN ._.
These_DT include_VBP different_JJ variants_NNS of_IN Lesk_NNP algorithm_NN or_CC most_RBS frequent_JJ sense_NN algorithm_NN ._.
Sense_NN inventory_NN ._.
WSD_NN exercises_NNS require_VBP a_DT dictionary_NN ,_, to_TO specify_VB the_DT word_NN senses_NNS which_WDT are_VBP to_TO be_VB disambiguated_VBN ,_, and_CC a_DT corpus_NN of_IN language_NN data_NNS to_TO be_VB disambiguated_VBN ._.
WordNet_NNP is_VBZ the_DT most_RBS popular_JJ example_NN of_IN sense_NN inventory_NN ._.
The_DT reason_NN for_IN adopting_VBG the_DT HECTOR_NNP database_NN during_IN Senseval-1_NN was_VBD that_IN the_DT WordNet_NNP inventory_NN was_VBD already_RB publicly_RB available_JJ ._.
Evaluation_NN measures_NNS ._.
During_IN the_DT evaluation_NN of_IN WSD_NNP systems_NNS two_CD main_JJ performance_NN measures_NNS are_VBP used_VBN :_: Precision_NN :_: the_DT fraction_NN of_IN system_NN assignments_NNS made_VBN that_WDT are_VBP correct_JJ Recall_VB :_: the_DT fraction_NN of_IN total_JJ word_NN instances_NNS correctly_RB assigned_VBN by_IN a_DT system_NN If_IN a_DT system_NN makes_VBZ an_DT assignment_NN for_IN every_DT word_NN ,_, then_RB precision_NN and_CC recall_NN are_VBP the_DT same_JJ ,_, and_CC can_MD be_VB called_VBN accuracy_NN ._.
This_DT model_NN has_VBZ been_VBN extended_VBN to_TO take_VB into_IN account_NN systems_NNS that_WDT return_VBP a_DT set_NN of_IN senses_NNS with_IN weights_NNS for_IN each_DT occurrence_NN ._.
